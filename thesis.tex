%%%%%
%%
%% Sample document ``thesis.tex''
%%
%% Version: v0.2
%% Authors: Jean Martina, Rok Strnisa, Matej Urbas
%% Date: 30/07/2008
%%
%% Copyright (c) 2008-2011, Rok Strni≈°a, Jean Martina, Matej Urbas
%% License: Simplified BSD License
%% License file: ./License
%% Original License URL: http://www.freebsd.org/copyright/freebsd-license.html
%%%%%

% Available documentclass options:
%
%   <all `report` document class options, e.g.: `a5paper`>
%   withindex   - enables the index. New index entries can be added through `\index{my entry}`
%   glossary    - enables the glossary.
%   techreport  - typesets the thesis in the technical report format.
%   firstyr     - formats the document as a first-year report.
%   times       - uses the `Times` font.
%   backrefs    - add back references in the Bibliography section
%
% For more info see `README.md`
%\documentclass[withindex,glossary,techreport]{cam-thesis}
%\documentclass[withindex,glossary]{cam-thesis}
\documentclass[]{cam-thesis}

% Citations using numbers
\usepackage[sort&compress,numbers]{natbib}
%\usepackage[numbers]{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{xcolor}
\usepackage{setspace}

\usepackage{caption}
\usepackage{subcaption}
\usepackage[bottom]{footmisc}
\usepackage{tikz-cd} 
\usepackage{amsthm}
\usepackage{bbm}
\usepackage{mathrsfs}
\usepackage{verbatim}
\usepackage{alphalph}
\usepackage{yhmath}
\usepackage{mathtools}
\usepackage{listings}
\usepackage{courier} 

%\usepackage[toc]{appendix}
\usepackage{bookmark}

%\onehalfspacing

%%% Commands

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{definition}{Definition}[section]
%\newtheorem*{remark}{Remark}

\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Thesis meta-information
%%

%% The title of the thesis:
\title{Rare events and dynamics in non-equilibrium systems}

%% The full name of the author (e.g.: James Smith):
\author{Lukas Takaaki Kikuchi}

%% College affiliation:
\college{Churchill college}

%% College shield [optional]:
\collegeshield{CollegeShields/CUniNoText}

%% Submission date [optional]:
% \submissiondate{November, 2042}

%% You can redefine the submission notice [optional]:
% \submissionnotice{A badass thesis submitted on time for the Degree of PhD}

%% Declaration date:
\date{October, 2022}

%% PDF meta-info:
\subjectline{Soft condensed matter and statistical physics}
\keywords{non-equilibrium-physics}

%\onehalfspacing

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Abstract:
%%
\abstract{%

The matter of this thesis is divided in two parts, both of which belong to disciplines that lie within the purview soft matter physics. In the first part, we study the infinite-dimensional probability space of stochastic differential equations. In particular, we study the ensemble of transition paths between meta-stable states of It\^{o} diffusions. We develop a suite of techniques to characterise the dominant transition channels of such systems, and study the character of the transition path ensemble as a function of varying diffusivity. 

rare events

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Acknowledgements:
%%
\acknowledgements{%
 % I would like to thank my supervisor, Ronojoy Adhikari, and his creativity and 
 % Mike Cates, Julian Kappler
 
 % Lastly, Lia Yolanda Ishan, Yedzin, Soogun
 % Perhaps one day we will all live in a commune
 % To the roll of a dice
 
 % for picking me up when
 
 % The one who rolls the dice up above.
 
% their love makes me everyday.
 
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Dedication:
%%
\dedication{%
To my friends.
%To me, myself and I, but most of all my friends.
%To me, myself and I, but most of all, to my friends.
%To me, myself and I.\footnote{But most of all, to my friends.}

  %To me, myself and I, but mostly my friends.
  % To me, myself and I, but most-
  % To the roll of a dice
  % To the dice roll
  % To the dice roller
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Glossary [optional]:
%%
%\newglossaryentry{HOL}{
%    name=HOL,
%    description={Higher-order logic}
%}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Contents:
%%
\begin{document}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Title page, abstract, declaration etc.:
%% -    the title page (is automatically omitted in the technical report mode).
\frontmatter{}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Thesis body:
%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% PART I : Introduction
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

This thesis explores two distinct topics. The first part concerns itself with the study of transition events in stochastic differential equations, both in regimes where these are ubiquitous as well as rare. The second part develops a geometrical theory of Cosserat materials \citep{cosseratTheoryDeformableBodies1909}, and further a generalised framework for studying continuum systems with configurations taking value in Lie groups or homogeneous spaces. Whilst substantially different, the two parts of this thesis do share a common trait in that they explore the geometry of spaces that possess an infinite-dimensional character. In essence, the research we present in the first part of the thesis quantitatively and qualitatively investigates the concentration of path-probability measures, defined over the infinite-dimensional space of stochastic transition paths. In the second part of this thesis, we consider systems with infinite degrees-of-freedom; that is, the systems are Lie group-valued \textit{manifolds} and we construct a general kinematic and dynamical theory of such systems in terms of their intrinsic geometry. Below we will separately introduce the two parts of this thesis.

\section*{Introduction to Part I}

Randomness is important on all scales in nature, and is ubiquitous in the mesoscopic scales of soft matter physics. Rich phenomena in physical, chemical and biological systems often emerge out of the interplay between stochastic and deterministic forces, as for example in the nucleation of solids, the conformational changes in biomolecules, or shifts in ecological balance \citep{faccioliDominantPathwaysProtein2006a, demarcoPhaseTransitionModel2001a, gardnerConstructionGeneticToggle2000a, mangelBarrierTransitionsDriven1994a, wolynesNavigatingFoldingRoutes1995a, huangMolecularMathematicalBasis2012a, paninskiMostLikelyVoltage2006a, noltingBallsCupsQuasipotentials2016a, leeFindingMultipleReaction2017a}. Mathematically, many systems of this kind can be modelled as overdamped Langevin dynamics, otherwise known as It\^{o} diffusions \citep{kampenStochasticProcessesPhysics2011a, gardinerStochasticMethodsHandbook2010a, riskenFokkerPlanckEquationMethods2012a, bharucha-reidElementsTheoryMarkov2012a}. The stochastic trajectories of such random processes tend concentrate around attractors in state-space, determined by the drift-field of the dynamics, which for conservative systems correspond to energetic minima. The influence of the stochastic forces renders the otherwise stable fixed points meta-stable, such that transitions between points or regions of meta-stability have finite probability. The set of all such transition paths between given meta-stable states is known as the transition path ensemble (TPE) \citep{bolhuisTransitionPathSampling2002a}. In Langevin models, the configuration of the system is often a reaction coordinate, and the characteristic pathways and rate constants of transition events are the main object of study \citep{dellagoCalculationReactionRate1999a, arjunUnbiasedAtomisticInsight2019, geisslerAutoionizationLiquidWater2001, carterConstrainedReactionCoordinate1989, laioEscapingFreeenergyMinima2002, bestMicroscopicInterpretationFolding2016, arjunUnbiasedAtomisticInsight2019}.

However transition events often occur on time-scales much larger than those of the dynamics itself \citep{petersReactionRateTheory2017, bolhuisTransitionPathSamplinga, grafkeLongTermEffects2017}. For example, the molecular dynamics of proteins are orders of magnitude smaller than the time-scale under which it unfolds \citep{veitshansProteinFoldingKinetics1997a}. In other words, transitions are \textit{rare events} for many relevant systems. Where analytical methods are intractable, numerical methods must be used to sample the transition path ensemble. However, it is in general not feasible to sample the TPE using standard stochastic integrators or molecular dynamics simulatons, due to the disparate time-scales of the target sample space and the dynamics. The study of the TPE must be approached via other means.

One such method is through the large deviation theory of Freidlin, Wentzell and Graham \citep{wentzellSmallRandomPerturbations1970, graham1987macroscopic}, which studies the TPE in the limit of vanishing noise, the so-called \textit{Freidlin-Wentzell limit}. The exponential scaling of transition rates in the noise-strength parameter can then be estimated by finding the global minimiser of an action functional. This minimiser, known as the \textit{instanton}, is the `least unlikely` pathway that the system will take in transition events, and any deviation from this path are exponentially suppressed in probability. However the limit of vanishing noise is unrealistic for many real physical systems, and some qualitative features of the transition paths may only emerge at finite temperatures \cite{pinskiTransitionPathsMolecules2010b}. In these regimes, sampling techniques must be used to sample the functional probability distribution over the TPE. Prominent examples of sampling methods are the \textit{transition path sampling} (TPS) \citep{dellagoTransitionPathSampling1998a, dellagoCalculationReactionRate1999a, dellagoEfficientTransitionPath1998, bolhuisTransitionPathSamplinga, bolhuisTransitionPathSampling2002a} and \textit{forward flux sampling} (FFS) \citep{escobedoTransitionPathSampling2009, allenForwardFluxSamplingtype2006, hussainStudyingRareEvents2020}. % Could add some stuff about the challenge of sampling multiple transiiton pathways.

In this first part of the thesis we offer some contributions to the study of the transition path ensemble of general overdamped Langevin systems, in both the Freidlin-Wentzell limit and at finite temperatures. In Ch.~\ref{ch:Ritz methods for Freidlin-Wentzel-Graham actions} we develop global methods of numerically minimising action functionals. The resulting method can be used to compute the \textit{quasi-potential} of general overdamped Langevin equations, which is a WKB-approximation of its steady-state distribution \citep{graham1987macroscopic, maier1996scaling, ludwig1975persistence}, as well the Freidlin-Wentzell instanton. 

In Ch.~\ref{ch:Monte Carlo methods in Path Spaces} we move on to consider transition path ensembles at finite temperatures. We begin with a survey of recent developments in the field of functional MCMC methods. We explain in detail the \textit{preconditioned Nicolson-Crank} algorithm \citep{cotterMCMCMethodsFunctions2013a, beskosMCMCMETHODSDIFFUSION2008a, hairerAnalysisSPDEsArising2005a, hairerAnalysisSPDEsArising2007a, hairerSpectralGapsMetropolis2014a}, which is an instance of an infinite-dimensional MCMC scheme. We apply this method to sample the TPE by expanding stochastic trajectories in the \textit{Kosambi-Karhunen-Lo\`eve} basis \citep{kosambiParallelismPathspaces2016, karhunenUeberLineareMethoden1947, loeveProbabilityTheory1977a} of the Brownian bridge process, which is a method by which Gaussian stochastic processes can be expressed in terms of an infinite series of independent Gaussian random numbers. In so doing, we find that spectrum of the non-Gaussian Langevin processes possess a band-structure, where only the lower-frequency band have non-trivial statistics; that is, we the infinite-dimensional space of stochastic transition paths, of a general overdamped Langevin system, admits an \textit{effective} finite-dimensionalisation. We utilised this band-separation to modify and improve the autocorrelation times of the pCN. The main result of this chapter is the construction of the \textit{teleporter MCMC} (TMC), which is a combination of the pCN method and a set of independence samplers. The latter are constructed, using a semi-classical expansion of the path-probability distribution around the locally most-probable paths of the TPE. This in turn allows the MCMC to `teleport' between dominant transition channels. The teleporter MCMC was designed to deal with the issue of \textit{slow mixing} \citep{holdenMixingMCMCAlgorithms2019}, which is a common problem faced by MCMC methods that sample target distributions where the local maxima lack mutual support in the sample space. In the context of transition paths, we have that methods like the pCN will in general fail to mix between multiple transition channels in a single run, thus generating a biased sample. The TMC circumvents this problem by allowing the Markov chain to intermittently teleport between the transition channels, using the independence samplers. Finally, a section in this chapter is also dedicated to discuss the relation between the mathematical notion of a path-probability measure (or \textit{law}), and the infinite-dimensional path-probability densities (and path integrals) which are ubiquitous in physics. We show that the latter, which are often understood by mathematicians and physicists alike to be of dubious mathematical rigour, can be recontextualised and even be made rigorous by understanding how they relate to well-defined mathematical objects.

In Ch.~\ref{ch:Diffusivity dependence of transition paths}, the final chapter of this part of the thesis, we apply and extend the methods of the previous chapter to study the concentration of competing transition channels in the TPE, as a function of temperature. Using two model systems, we show that the dominant transition channel does not in general coincide with the most probable path of the path measure, even in a low-to-intermediate temperature regime. We construct a semi-analytical approximation of the TPE as mixture of Gaussian measures using the semi-classical expansion of the path-probability distribution. We then apply this approximate probability measure to estimate the relative probability of competing transition channels. We verify the validity of these estimators using the MCMC methods developed in the previous chapter. We also demonstrate, using the model systems, that the interplay between fluctuations and drift can lead to the unintuitive result of energetically unfavourable transition channels dominating over the energetically favourable channels.

\section*{Introduction to Part II}

A wide range of structures exhibit properties of softness and slenderness, from biological materials like cilia \citep{guMagneticCiliaCarpets2020} and cellular membranes \citep{krishnaswamyCosserattypeModelRed1996}, to strands of DNA \citep{corazzaUnravelingLoopingEfficiency2022} and hydrogels \citep{rajanMechanicsViscoelasticBuckling2019}. In this instance `soft' refers to the constitutive properties of the material, like that of rubber or biological tissue, and `slender' refers to its geometrical thinness.

- Also include references to research that have been done using cosserat theory.



In geometry part, you can talk about how intro, cosserat and geometry chapters serve as three successive dry runs of the same thing.

"On the other hand, geometrical methods have revolutionized the field of classical
mechanics since its inception, yielding some of the most important analytical techniques
available in modern physics. These include Lie‚Äôs theory of dimensional reduction through
symmetries, and the alternative formulation"



Many systems in noneq where you have diffusions on lie groups.

Mention what the difficulties are with the conventional methods.

Maybe incorporate stuff from your talk in the geometry part of the intro. triangulasiont coordinitisation. It is general difficult to triangulate a principal fibre bundle.





In Ch.~\ref{eq:geometry introduction} we began our study of the geometric continuum mechanics of systems with Lie group- or homogeneous configuration spaces. We reviewed the classical theories that our work builds on, and developed the necessary mathematical tools for the results of the subsequent chapters. Of these, the mathematical preliminaries, though dense, by itself foreshadows and serves as a dry-run for the geometrical treatment that was to come.

In Ch.~\ref{ch:Cosserat rods} we derived the kinematic and dynamic - in short, kinodynamic - equations of Cosserat rods and filaments. These were chosen as paradigmatic examples of systems with Lie group- and homogeneous configuration spaces, and served as a foundation for the generalisations of the chapter that followed. We identified the configuration space of the Cosserat rod as the special Euclidean group $SE(3)$, and used the Euler-Poincar√© theorem to find conservative force and moment balance equations. Furthermore, we constructed a generalised Lagrange-D'Alembert principle from which arbitrary non-conservative dynamics can be derived, and expressed the resulting kinodynamic equations of motion in terms of a spatial reconstruction field $X$ and generalised momentum field $S$, which are defined on the Lie algebra and its dual respectively. This Lie algebraic formulation was shown to naturally lead to kinodynamics expressed in terms of the intrinsic geometry of the rod. We then studied the filament model, which we devised as a Cosserat rod subject to kinematic constraints, and found its kinodynamic equations of motion. We thus demonstrated how systems with homogeneous configuration spaces can be obtained by imposing kinematic constraints on Lie group-configured systems.

In Ch.~\ref{ch:Geometric continuum mechanics on homogeneous configuration spaces} we studied generalised Cosserat systems, which we defined as continuum bodies with a material base of general topology, and Lie group- or homogeneous configuration spaces. We formulated a general theory of the kinodynamics of such systems, which we called a generalised geometric Cosserat theory (GGCT). The cornerstone of the programme was to use the exponential map to relate the spatio-temporal configuraiton of the system to Lie algebra-valued reconstruction fields. This allowed us to express the kinodynamics of generalised Cosserat systems directly in terms of its intrinsic geometry. We applied the GGCT to derive the kinodynamic equations of motion for a variety of known and new systems, which included the classical suite of Cosserat surfaces and bodies, Cosserat rods on spheres and in Minkowski space, as well as an application for non-linear $\sigma$ field theory.

In Ch.~\ref{ch:Geometric numerical integrators} we developed geometric integrators for generalised Cosserat systems. We saw this as an application of Lie group integration theory to the infinite-dimensional setting of continuum systems. We demonstrated that our integrators preserve spatial integrability using the example of a Cosserat surface, and compared their performance to standard non-geometrical numeric integrators. We also showed that other qualitative features, like the closure of a rod, are preserved by our integrators.














%%%% Introduce soft and slender matter and give examples.
% Todo:
% - Include soft robotics as example



%Cosserat theories are being used to describe an increasing number of physical phenomena. For example, Green, Naghdi and their coworkers have developed Cosserat theories for many applications which include: shells (Naghdi, 1972); rods (Green et aI., I 974a,b); fluid jets and sheets (Naghdi, 1979); electromagnetic effects in shells (Green and Naghdi, 1983) and rods (Green and Naghdi, 1985); turbulence (Marshall and Naghdi, 1989a,b); microcrack growth (Marshall et aI., 1991); composite materials (Green and Naghdi, 1991); and a model of dislocations in three-dimensional plasticity theory (Naghdi and Srinivasa, 1993a,b). In addition, a computer search of the Compendex and Inspec data bases indicates that Cosserat theories are also being used to describe: finite elements (Simo and Fox, 1989), (Simo et aI., 1989) and (Simo et aI., 1990); shearbanding and liquefaction in granular materials (Vardoulakis, 1989); fracture of bone (Lakes et aI., 1990); size effects in rocks (Sulem and Vardoulakis, 1990) and foams (Lakes, 1993); liquid bridges subjected to microgravity (Meseguer and Perales, 1992); grain rotations in granular media (Alehossein and Muhlhaus, 1994); suppression of localization in plasticity (De Borst, 1991; Iordache and Willam, 1995); fracture scaling parameters of inhomogeneous microstructure in composites (Cairns et a!., 1995); micromechanics of inclusions (Cheng and He, 1995) and failure of welds (Craine and Newman, 1996)

We develop a general geometric theory of the kinematics and dynamics of $G$ or $G/H$-valued systems. We show in particular that the continuum mechanics of all directed media, otherwise known as Cosserat media, can be unified in description using this framework. As a special case, we also recover classical (undirected) continuum mechanics, expressed in Cartan's theory of moving frames.

---

Make it clear what is new: The general geometric framework and the Lie group integrators, as well as the presentation of all of the various Cosserat theories through the same framework.

Whilst the connection between Lie groups and mechanics has long been studied \citep{marsdenIntroductionMechanicsSymmetry2013}, here we provide a theory of mechanics Lie group-valued continua.

At a level of abstraction sufficient to describe all Cosserat theories, but also more general systems. For example, the framework is amenable to relativistic systems as well.

A lot of the results have already been shown before (a lot of the stuff in the Cosserat rod section in particular). The main purpose is to show how it all falls out of the a unified framework, and also works as a review article to some extent.


 In this thesis, we 
 
 In the second part of this thesis
 
 Mention that the two parts can be combined by deriving stochastic dynamics for part 2 systems and the field stuff for part 1.

in all the subsection conclusions, you will talk about further work. here you can summarise the further work.

















\include{thesis_part1}

\include{thesis_part2}


\bookmarksetup{startatroot}
\chapter*{Summary}
\addcontentsline{toc}{chapter}{Summary}
 
The research presented in this thesis divides into two parts. In the first part, we studied and developed methods for studying the transition path ensemble of It\^{o} diffusion equations. In the second part, we developed a geometric theory of continuum mechanics of systems with Lie group- or homogeneous configuration spaces. Below we summarise the main results of each chapter of the two research streams discussed in this thesis.


In Ch.~\ref{ch:Ritz methods for Freidlin-Wentzel-Graham actions} we began our exploration of the transition path ensemble by considering the Freidlin-Wentzell limit, which corresponds to a limit of vanishing diffusivity. We presented numerical methods for computing most probable transition paths and quasi-potentials of general It\^{o} diffusion equations with additive noise. The method directly minimises the Freidlin-Wentzell action, which allowed for flexibility in choosing the path parametrisation. It uses numerical quadrature to reduce the action to a multivariate function, whose minimum is obtained by either gradient-free and gradient-based optimisation. This provides both the minimum action path and quasipotential. The direct method consisted of a discretisation of the Freidlin-Wentzell action, followed by a search for the minimum in the resulting finite-dimensional space. This approach is algorithmically simple and we showed its accuracy and efficiency on a number of benchmark problems.

In Ch.~\ref{ch:Monte Carlo methods in Path Spaces} we considered the TPE at finite temperatures. We applied recent mathematical developments in the field of functional Markov chain Monte Carlo methods to the sampling of stochastic transition pathways. On this foundation, we developed an MCMC scheme designed to sample TPEs with multiple competing transition channels, which we called the teleporter MCMC. The method was based on a semi-classical expansion of the path-probability measure around the dominant transition pahs of the distribution, with which we constructed independence samplers allowing for the MCMC to intermittently `teleport' between transition channels. Akin to the Ritz method of the Ch.~\ref{ch:Ritz methods for Freidlin-Wentzel-Graham actions}, the MCMC procedures were discretised using a global spectral basis. Speficially, we expanded stochastic paths in the Kosambi-Karhunen-Lo\`eve of the Brownian bridge process. We showed that spectrum of modes in this expansion can be separated into high- and low-frequency bands, where only the lower-band modes are non-trivially distributed, whilst the statistics of the latter is indistinguishable from that of free diffusion. Future research directions may involve devising multi-level MCMC schemes designed around band-structure of the KKL-based methods we developed in this chapter. Furthermore, we may consider extending the algorithm to sample transition path ensembles of field theories. 

In Ch.~\ref{ch:Diffusivity dependence of transition paths} we studied the concentration of competing transition channels in the transition path ensemble, as a function of diffusivity. Using two model systems, we showed that the dominant transition channel does not in general coincide with most probable paths of the path measure, even in a low-to-intermediate temperature regime. We approximated the TPE as mixed Gaussian measures using the semi-classical expansions developed in the previous chapter, using which we constructed semi-analytical approximators of channel rate probabilities. In the regime of validity of these approximators, we showed that the relative dominance of transition channels is a conspiracy between the path-probability of the instanton, reflecting the energetic cost of transition, and Gaussian normalisation constants, reflecting the fluctuations around the instanton.

In Ch.~\ref{eq:geometry introduction} we began our study of the geometric continuum mechanics of systems with Lie group- or homogeneous configuration spaces. We reviewed the classical theories that our work builds on, and developed the necessary mathematical tools for the results of the subsequent chapters. Of these, the mathematical preliminaries, though dense, by itself foreshadows and serves as a dry-run for the geometrical treatment that was to come.

In Ch.~\ref{ch:Cosserat rods} we derived the kinematic and dynamic - in short, kinodynamic - equations of Cosserat rods and filaments. These were chosen as paradigmatic examples of systems with Lie group- and homogeneous configuration spaces, and served as a foundation for the generalisations of the chapter that followed. We identified the configuration space of the Cosserat rod as the special Euclidean group $SE(3)$, and used the Euler-Poincar√© theorem to find conservative force and moment balance equations. Furthermore, we constructed a generalised Lagrange-D'Alembert principle from which arbitrary non-conservative dynamics can be derived, and expressed the resulting kinodynamic equations of motion in terms of a spatial reconstruction field $X$ and generalised momentum field $S$, which are defined on the Lie algebra and its dual respectively. This Lie algebraic formulation was shown to naturally lead to kinodynamics expressed in terms of the intrinsic geometry of the rod. We then studied the filament model, which we devised as a Cosserat rod subject to kinematic constraints, and found its kinodynamic equations of motion. We thus demonstrated how systems with homogeneous configuration spaces can be obtained by imposing kinematic constraints on Lie group-configured systems.

In Ch.~\ref{ch:Geometric continuum mechanics on homogeneous configuration spaces} we studied generalised Cosserat systems, which we defined as continuum bodies with a material base of general topology, and Lie group- or homogeneous configuration spaces. We formulated a general theory of the kinodynamics of such systems, which we called a generalised geometric Cosserat theory (GGCT). The cornerstone of the programme was to use the exponential map to relate the spatio-temporal configuraiton of the system to Lie algebra-valued reconstruction fields. This allowed us to express the kinodynamics of generalised Cosserat systems directly in terms of its intrinsic geometry. We applied the GGCT to derive the kinodynamic equations of motion for a variety of known and new systems, which included the classical suite of Cosserat surfaces and bodies, Cosserat rods on spheres and in Minkowski space, as well as an application for non-linear $\sigma$ field theory.

In Ch.~\ref{ch:Geometric numerical integrators} we developed geometric integrators for generalised Cosserat systems. We saw this as an application of Lie group integration theory to the infinite-dimensional setting of continuum systems. We demonstrated that our integrators preserve spatial integrability using the example of a Cosserat surface, and compared their performance to standard non-geometrical numeric integrators. We also showed that other qualitative features, like the closure of a rod, are preserved by our integrators.






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% References:
%%
% If you include some work not referenced in the main text (e.g. using \nocite{}), consider changing "References" to "Bibliography".
%

% \renewcommand to change default "Bibliography" to "References"
\renewcommand{\bibname}{References}
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{References}
%\bibliographystyle{plainnat}

\bibliographystyle{unsrtnat}
%\bibliography{refs/parti, refs/partii, refs/fluctuations_around_instantons, refs/nucleation, refs/path-integrals, refs/rare_events, refs/diffus_refs1, refs/diffus_refs2}
\bibliography{refs/parti, refs/partii}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Appendix:
%%

\cleardoublepage
\phantomsection
\appendix
\addcontentsline{toc}{part}{Appendices}

%\begin{appendices}

%\chapter{Moving frames for sub-manifolds of $SE(d)$} \label{app:Moving frames for sub-manifolds of SE(d)}

\chapter{MCMC benchmark models} \label{app:MCMC benchmark models}

Here we define the Langevin model systems considered in Ch.~\ref{ch:Monte Carlo methods in Path Spaces} and Ch.~\ref{ch:Diffusivity dependence of transition paths}. We begin by defining a non-dimensionalised formulation of the Langevin equation with additive noise
\begin{equation}
d\mathbf{X}=\mu\mathbf{F}dt+\sqrt{2D}d\mathbf{W}.
\end{equation}
where $\mu$ is the mobility constant and $D$ the diffusion constant. We write the latter as $D = \mu k_B \theta$, where $k_B$ is the Boltzmann constant $\theta$ is the temperature. We assume that the force is the gradient of a potential energy function $U : \mathbb{R}^d \to \mathbb{R}$  as $\mathbf{F} = - \nabla \cdot U$.

Let $T_{0}=\frac{L^{2}}{k_{B}\theta_{0}\mu}$ be a time-scale, $\theta_{0}$ a temperature-scale, and $L_0$ a characteristic length-scale of the potential. We set $t=T_{0}\tilde{t}$,
$\theta=\theta_{0}\tilde{\theta}$, $\mathbf{X}=L_0 \tilde{\mathbf{X}}$,
$\mathbf{F}= \frac{\tilde{U}_0}{L_0} \tilde{\mathbf{F}}$ and $\mathbf{W}=\sqrt{T_{0}}\tilde{\mathbf{W}}$. $T_{0}$ is the typical diffusion time-scale at temperature $\theta_{0}$. We get
\begin{equation}
	d\mathbf{\tilde{X}}=\tilde{U}_{0} \tilde{\mathbf{F}}d\tilde{t}+\sqrt{2\tilde{\theta}}d\tilde{\mathbf{W}}.
\end{equation}
where all quantities in the equation are now non-dimensional, and where $\tilde{U}_{0}=\frac{U_{0}}{k_{B}\theta_{0}}$ is the ratio
of the energetic well-depth $U_{0}$ and the thermal energy at temperature $\theta_{0}$. We set $\tilde{U}_0 = 1$, such that $\theta = \theta_0$ corresponds to the temperature at which $U_0 = k_B \theta_0$. In other words, the characteristic energy scale of the potential is equal to the thermal energy at temperature $\theta_0$. Finally, the non-diemsionalised Langevin equation is
\begin{equation}
	d\mathbf{\tilde{X}}= \tilde{\mathbf{F}}d\tilde{t}+\sqrt{2\tilde{\theta}}d\tilde{\mathbf{W}}.
\end{equation}

\section{The asymmetric double-well system} \label{app:The asymmetric double-well system}

\begin{figure}[t]
\includegraphics[width=0.6\textwidth]{figs_part1/mcmc/1D_process_potential}
\centering \caption{The asymmetric double-well potential, with minima at $x/L_0 = -1$ (hollow red circle) and $x/L_0=1$ (filled red circle). See App.~\ref{app:The asymmetric double-well system} for its definition.}
\label{fig:1D process potential} 
\end{figure}

Consider a $1$-dimensional Langevin system with a quartic potential
\begin{equation} \label{eq:general quartic potential}
	U(x) = U_0 \left( 1 + a \frac{x}{L_0} + b \left( \frac{x}{L_0} \right)^2 + x \left( \frac{x}{L_0} \right)^3  + d \left( \frac{x}{L_0} \right)^4  \right).
\end{equation}
We impose the following conditions
\begin{enumerate}
\item $U'(-L_0) = U'(L_0) = 0$. Extrema at $x = -L_0$ and $x= L_0$.
\item $U(-L_0) = 0$ and $U(L_0) = \Delta U$. The energy cost of moving from the left-most extremum to the right-most extremum is $\Delta U$.
\end{enumerate}
Imposing the conditions on Eq.\ref{eq:general quartic potential}, we get
\begin{equation}  \label{eq:asymmetric double well}
U(x)= \left( \left(\frac{x}{L_0}-1\right)^{2}-\frac{1}{4}\frac{\Delta U}{U_{0}}\left(\frac{x}{L_0}-2\right)\right)\left(\frac{x}{L_0}+1\right)^{2}. 
\end{equation}
Equation \ref{eq:asymmetric double well} defines an \textit{asymmetric} variant of a standard quartic double-well system, with minimii at $\frac{x}{L_0}= -1$ and $\frac{x}{L_0}=1$, and a maximum at $\frac{x}{L_0} = \frac{ 3 \Delta U}{16 U_0}$. See Fig.~\ref{fig:1D process potential} for a depiction of the potential energy landscape. In non-dimensionalised form, the potential is
\begin{equation}  \label{eq:asymmetric double well nondim}
\tilde{U}(\tilde{x})= \left( \tilde{x}-1\right)^{2} - \frac{1}{4} \frac{\Delta U}{U_{0}} \left( \tilde{x}-2 \right) \left(\tilde{x}+1\right)^{2}. 
\end{equation}
where $\tilde{x} = x / L$. In all numerical simulations, we have set $\frac{\Delta U}{U_{0}}=1/2$.

\section{The switch system} \label{app:The switch system}

Here we define the \textit{switch} system, and its non-conservative variant used in Ch.~\ref{ch:Diffusivity dependence of transition paths}. We consider a $2$-dimensional Langevin system with a Sombrero-type potential $U : \mathbb{R}^2 \to \mathbb{R}$. Let $\Gamma=\{(x,y)\ |\ \sqrt{x^2 + y^2} =1\}$ be the circle centred around the origin, and let $\Gamma^{+}$ and
$\Gamma^{-}$ signify the upper and lower semi-circle respectively. We will a construct the potential such that $\Gamma$ coincides with a manifold of potential minima, and such that the perpendicular curvature of the potential along $\Gamma^{+}$ is larger than along $\Gamma^{-}$. We
start with a radial quartic potential of the form 
\begin{align}
U(x_{1},x_{2}) & =U_{r}(r(x_{1},x_{2}))\\
U_{r}(r) & =U_{0}\left(\frac{r}{L_0}-1\right)\left(1+a\frac{r}{L_0}+b\left(\frac{r}{L_0}\right)^{2}+c\left(\frac{r}{L_0}\right)^{3}\right)\nonumber 
\end{align}
where $L_0$ is the length-scale of the system, $U_{0}$ will be the
value of the potential at the local maximum $r=0$, and $a,b,c\in\mathbb{R}$
will be specified below. We will henceforth suppress the argument of
the radial coordinate function $r(x_{1},x_{2})=\sqrt{x_{1}^{2}+x_{2}^{2}}$. We
impose the following conditions on the potential to fix $a, b$ and $c$:
\begin{enumerate}
\item $U_r'(0) = 0$. The origin is an extremum.
\item $U_r'(L_0) = 0$. $\Gamma$ is an extremum of the potential.
\item $U_r''(L_0) = k$. The curvature along $\Gamma$ is $k$.
\end{enumerate}
We get
\begin{equation}
U_{r}(r)=\frac{1}{2}\left(\frac{r}{L_0}-1\right)^{2}\left[L_0^{2} k \left(\frac{r}{L_0}\right)^{2}-2U_{0}\left(\frac{r}{L_0}-1\right)\left(3\frac{r}{L_0}+1\right)\right]
\end{equation}
which is, in the non-dimensionalised form
\begin{equation}
\tilde{U}_{r}(\tilde{r})= \frac{1}{2} 
\left( \tilde{r} -1 \right)^{2} \left[L_0^{2} \tilde{k} \tilde{r}^{2}-2  
\left(\tilde{r}-1\right)\left(3\tilde{r}+1\right)\right].
\end{equation}
where $\tilde{r} = r / L$ and $\tilde{k} = \frac{k}{U_0}$. In order to ensure that the potential has a Sombrero-like form, we
must further have that the potential is confining, which is equivalent
to $\underset{r\to\infty}{\lim}U_{r}(r)=\infty$, which implies that
$6U_{0}\leq L_0^{2}k$. We now introduce an angular dependence in the
curvature. We set
\begin{equation}
L_0^{2}k(\phi)=6U_{0}(1+2h(\phi))\label{eq:curvature}
\end{equation}
where $\phi=\phi(x_{1},x_{2})$ is the angle of $(x_{1},x_{2})$ in
polar coordinates so that $x_{1}=\cos(\phi)$, $x_{2}=\sin(\phi)$,
and where
\begin{equation}
h(\phi)=\frac{1}{4}\left(\xi_{2}+\xi_{1}+(\xi_{2}-\xi_{1})\sin\phi\right)
\end{equation}
where $\xi_{2}>\xi_{1}$, and where $h(\phi)\in[\xi_{1},\xi_{2}]$
satisfies $h(-\pi/2)=\xi_{1}$ and $h(\pi/2)=\xi_{2}$. Eq.~\eqref{eq:curvature}
is constructed so that the perpendicular curvature of $\Gamma^{+}$
is larger than that of $\Gamma^{-}$. The drift of the system is now
given by $\mathbf{F}=-\nabla U$. This concludes the definition of the switch system.

We also consider a non-conservative variant of the switch system. We introduce an additional non-conservative
force $\mathbf{F}^{a}=-\eta\hat{\boldsymbol{\phi}}$ for which the
work done in a displacement $d\mathbf{x}=dr\hat{\mathbf{r}}+rd\phi\hat{\boldsymbol{\phi}}$
is $dW=\mathbf{F}^{a}\cdot d\mathbf{x}=\eta rd\phi$. This force energetically
biases the upper transition channel $\Gamma^{+}$. The total force
is thus $\mathbf{F}=-\nabla U+\mathbf{F}^{a}$.

In the numerical experiments presented in the main text, we used the
It√¥ Langevin equation 
\begin{equation}
d\mathbf{X}=\mu\mathbf{F}dt+\sqrt{2\mu k_{B}\theta}d\mathbf{W}.\label{eq:langevin equation}
\end{equation}
For the numerical experiments in the main text  we use $\tilde{U}_{0}=1$,
which means that $\tilde{\theta}=1$ corresponds to a temperature
such that $k_{B}\theta=U_{0}$. We also set $\xi_{1}=0$ and $\xi_{2}=2$.
To compare the gradient force $-\nabla \cdot U$ with $\mathbf{F}^{a}$ we also introduce
$f_{\text{eq}}=U_{0}/L$, which is the characteristic force strength
of the gradient force.

\chapter{Calculating the regularised normalisation constants of infinite-dimensional Gaussian measures} \label{app:Calculation of the Gaussian normalisation constants}

The regularised normalisation constants of Gaussian measures defined on functional
spaces can be found by computing the determinants of their covariance
operators. Equivalently, they can be found by computing
the determinant of their precision operator, which is the inverse
of the covariance operator. As for finite-dimensional linear operators,
determinants of differential operators can be found by computing the product of their
eigenvalues, but as the numerical computation of the spectrum of a linear operator is expensive, this is in general not feasible in this setting. For a specific class of linear operators, their regularised normalisation constants can be computed using the Gelfand-Yaglom theorem (GYT) \citep{gelfandIntegrationFunctionalSpaces1960a, levitTheoremInfiniteProducts1977a, dunneFunctionalDeterminantsQuantum2008a}, by solving a system of ODEs. Here we will first recount the GYT, and then derive an extension of theorem that can be used for the precision operators of the semi-classical expansions of the laws of general It\^{o} processes with additive noise.

Let the linear operators
\begin{equation}
\mathcal{L}=\frac{d}{dt}\left(P\frac{d}{dt}\right)-R\label{eq:linear operator}
\end{equation}
and
\begin{equation}
\mathcal{L}_{0}=\frac{d}{dt}\left(P\frac{d}{dt}\right)\label{eq:free linear operator}
\end{equation}
be defined for $0\leq t\leq T$, and where $P(t)\in\mathbb{R}^{d\times d}$
is a symmetric positive-definite matrix function and $R(t)\in\mathbb{R}^{d\times d}$
is a symmetric matrix function. Let $\gamma^{(k)}$ and $\mathbf{u}^{(k)}(t;\alpha)$
be the eigenvalues and eigenfunctions of $\mathcal{L}$, which are
solutions to the boundary value problem
\begin{equation}
\mathcal{L}\mathbf{u}^{(k)}(t)=\gamma^{(k)}\mathbf{u}^{(k)}(t)\label{eq:eigenfunction eq}
\end{equation}
where $\mathbf{u}^{(k)}(0)=\mathbf{u}^{(k)}(T)=0$. Similarly, let
$\mathbf{u}_{0}^{(k)}(t)$ and $\gamma_{0}^{(k)}$ be the eigenfunctions
and eigenvalues of $\mathcal{L}_{0}$. Then the \emph{functional determinant}
of $\mathcal{L}$ is defined in regularised form as
\begin{equation}
\frac{\det\mathcal{L}}{\det\mathcal{L}_{0}}=\prod_{k=1}^{\infty}\frac{\gamma^{(k)}}{\gamma_{0}^{(k)}}.\label{eq:functional determinant}
\end{equation}
As the spectrum of Eq.~\ref{eq:linear operator} is unknown, and
numerically expensive to compute, a much more efficient way of computing
Eq.~\ref{eq:functional determinant} is via the GYT.
The GYT states that the functional determinant can be expressed as
\begin{equation}
\left|\frac{\det\mathcal{L}}{\det\mathcal{L}_{0}}\right|=\left|\frac{\det\left[Y(T)\right]}{\det\left[Y_{0}(T)\right]}\right|\label{eq:GY result}
\end{equation}
where $Y(t)\in\mathbb{R}^{d\times x}$ with components $Y_{ij}(t)=y_{i}^{(j)}(t)$,
where the $\mathbf{y}^{(j)}(t)$ are solutions to the $d$ second-order
ODEs with initial conditions
\begin{align} 
\mathcal{L}\mathbf{y}^{(j)}(t) & =0\label{eq:GY theorem}\\
\mathbf{y}^{(j)}(0) & =0\\
\frac{d}{dt}y_{i}^{(j)}(0) & =\delta_{ij}.
\end{align}
and where the matrix $Y_{0}(t)\in\mathbb{R}^{d\times d}$
is defined similarly, but with $\mathcal{L}$ in Eq.~\ref{eq:GY theorem}
replaced with $\mathcal{L}_{0}$. We now present a generalisation of the GYT that allows for linear operators of the form
\begin{equation} \label{eq:extended GYT form operator}
\mathcal{L}=\frac{d^{2}}{dt^{2}}+U\frac{d}{dt}+R
\end{equation}
where $0\leq t\leq T$, and where $U(t),\ R(t)\in\mathbb{R}^{d\times d}$
are anti-symmetric and symmetric matrix functions respectively. This extended GYT will make the theorem applicable to compute the regularised normalisation constants of the precision operators discussed in Sec.~\ref{sec:Second-order variational expansions of stochastic action functionals}.

We define the linear operator $\mathcal{G}$ which acts on vector
functions as
\begin{equation} \label{eq:G op}
	\mathcal{G}\mathbf{y}=G\mathbf{y}
\end{equation}
where $G(t)$ is a matrix function that solves the equation
\begin{equation}
\dot{G}=-\frac{1}{2}UG.\label{eq:G eq}
\end{equation}
As $U(t)$ is anti-symmetric we have $U(t) \in \mathfrak{so}(d)$, where the latter is the Lie algebra of the special orthogonal group $SO(d)$. Then Eq.~\ref{eq:G eq} is the exponential mapping from the Lie algebra to the Lie group, therefore $G \in SO(d)$. We define the linear operator
\begin{equation} \label{eq:transformed linear operator}
\tilde{\mathcal{L}}=\mathcal{G}^{-1}\mathcal{L}\mathcal{G}=\frac{d}{dt^{2}}+G^{T}\left(R-\frac{1}{2}\dot{U}-\frac{1}{4}U^{2}\right)G
\end{equation}
where we have used $G^{-1} = G^T$. Equation \ref{eq:transformed linear operator} is of the form Eq.~\ref{eq:linear operator}, as the second term is a symmetric matrix, and we can therefore compute $\det\tilde{\mathcal{L}}$ using the GYT. As for any two operators $\mathcal{A}$
and $\mathcal{B}$, we have that $\det\mathcal{A\mathcal{B}}=\det\mathcal{A}\det\mathcal{B}$,
and $\det\mathcal{A}^{-1}=1/\det\mathcal{A}$, and we therefore have
that $\det\mathcal{L}=\det\tilde{\mathcal{L}}$. The functional determinant
$\det\mathcal{L}$ can thus be computed by first solving Eq.~\ref{eq:G eq}, and then
constructing $\tilde{\mathcal{L}}$ using Eq.~\ref{eq:transformed linear operator},
and finally using the GYT to compute $\det\tilde{\mathcal{L}}$.

The above can be applied to compute the regularised normalisation constants of the precision operators derived in Sec.~\ref{sec:Second-order variational expansions of stochastic action functionals}, which were the result the semi-classical approximations of the path measures of general It\^{o} diffusions with additive noise. The precision matrix is of the form
\begin{equation}
	\mathcal{H}^{[\bar{\mathbf{x}}]} =-\frac{1}{D} \frac{d}{dt^{2}}+2A\frac{d}{dt}+B
\end{equation}
We can compute the regularised normalisation constant of $\mathcal{H}^{[\bar{\mathbf{x}}]}$ by letting $P(t)=-\frac{1}{D} \mathbbm{I}_{d}$, $U=-2 D A$ and $R=B$ and applying the extended GYT. In the case of gradient dynamics, when $A = 0$, the original GYT can be readily applied by using $P(t)=-\frac{1}{D} \mathbbm{I}_{d}$ and $R(t)=-B(t)$, where $\mathbbm{I}_{d}$ is the identity matrix.


\chapter{Reconstructing the spatio-temporal configuration} \label{app:Reconstructing the spatio-temporal configuration}

To reconstruct the spatio-temporal configuration $\Phi(t, \mathbf{u})$ of a system from its spatial reconstruction fields $X_\alpha(t, \mathbf{u})$ and generalised velocity field $N(t,\mathbf{u})$, where $\mathbf{u} \in M$, we must solve the equation
\begin{equation} \label{eq:app phi and xi gen}
	\Phi^{-1} d \Phi = \xi
\end{equation}
where $\xi = N dt + X_\alpha du^\alpha$. Given some initial condition $\Phi(\bar{t}, \mathbf{u}_0)$, we can find $\Phi(\bar{t},\mathbf{u})$ by integrating Eq.~\ref{eq:app phi and xi gen} for fixed $\bar{t}$ along some curve $\gamma : [0,1] \to M$ that satisfies $\gamma(0) = \mathbf{u}_0$ and $\gamma(1) = \mathbf{u}$. If $X_\alpha$ satisfy spatial integrability, the result of this integration is independent of the shape of the path $\gamma$.

A numerical scheme for reconstructing the spatio-temporal configuration can thus be devised by repeatedly integrating Eq.~\ref{eq:app phi and xi gen} along curves that trace out $\Phi$ along the desired points $\mathbf{u} \in M$. In the following section we will show such a scheme explicitly for the case of the Cosserat rod, and the procedure can be readily generalised to higher-dimensional systems.

\section{Numerical algorithm for reconstructing the Cosserat rod} \label{app:Reconstructing the Cosserat rod from xi}

Here we describe how to reconstruction the spatio-temporal configuration of a Cosserat rod $\Phi(t,u)$ from the spatial reconstruction field $X(t,u)$ and generalised velocity field $N(t,u)$. These are related as Eq.~\ref{eq:app phi and xi gen}, where $\xi = X du + N dt$, from which we have
\begin{subequations} 
\begin{align}
\Phi' & =  \Phi X \label{eq:F u} \\
\dot{\Phi} & = \Phi  N \label{eq:F t}.
\end{align}
\end{subequations}
Formally, these have solutions
\begin{subequations} 
\begin{align}
\Phi_{ij}(u, \bar{t}) & = \Phi_{ik}(0, \bar{t}) \mathscr{U} \left\{ e^{ \int_0^u X(u, \bar{t}) du } \right\}_{kj} \\
\Phi_{ij}(\bar{u}, t) & = \Phi_{ik}(\bar{u}, 0) \mathscr{T} \left\{ e^{ \int_0^t N(\bar{u}, t) dt } \right\}_{kj}
\end{align}
\end{subequations}
where $\mathscr{U}(\cdot)$ and $\mathscr{T}(\cdot)$ signifies the spatial and temporal time-ordered integral respectively. Numerically, these can be efficiently approximated by discretisation, and incrementally solved using the \textit{Magnus expansion} \citep{magnusExponentialSolutionDifferential1954}. Eq. \ref{eq:F u} and Eq. \ref{eq:F t}
can therefore be used together to trace out $\mathcal{F}$
from a single initial condition $\Phi(u_{0}, t_{0})$. Due to
the integrability of $\xi$, the value $\Phi(t, u)$ at $(t, u)$ is invariant with respect to which particular path
in $(t, u)$-space is taken. In light of this there are theoretically
an infinite number of reconstruction schemes. Below we propose what
we find to be the most convenient reconstruction scheme.

We discretise time and space as $u_{\alpha}=\alpha\Delta u,\ \alpha=0,\dots,N_{u}$, such that $u_{0}=t_{0}=0$ and $t_{\beta}=\beta\Delta t,\ \beta=0,\dots,N_{t}$
and $u_{N_{u}}=L_{0}$ and $t_{N_{t}}=T$. We define $\Phi^{\alpha,\beta}\approx \Phi(\alpha\Delta u,\beta\Delta t)$,
$X^{\alpha,\beta}\approx X(\alpha\Delta u,\beta\Delta t)$ and $Y^{\alpha,k}\approx Y(\alpha\Delta u,\beta\Delta t)$.
\begin{subequations} \label{eq:numerical schema for reconstruction of Cosserat rod}
\begin{align}
\Phi_{ij}^{0, \beta+1} & = \Phi_{ik}^{0, \beta} \exp_{SE(3)} \left(\Delta t\ N^{0, \beta}\right)_{kj}, & \Phi^{0,0}=\Phi^{(i)}\\
\Phi_{ij}^{\alpha+1, \beta} & = \Phi_{ik}^{\alpha, \beta}\exp_{SE(3)}  \left(\Delta u\ X^{\alpha,\beta}\right)_{kj} \label{eq:F spatial numerical eq}
\end{align}
\end{subequations}
with the initial condition $\mathcal{F}^{0,0}=\mathcal{F}^{(i)}$.
The matrix exponential has a closed-form analytical formula given
by
\begin{equation}
\exp_{SE(3)}  (H)=\left(\begin{array}{cc}
1 & \vec{0}^{T}\\
\mathscr{B}(\hat{m}) \vec{v} & \exp_{SO(3)}(\hat{m})
\end{array}\right)
\end{equation}
for $H=\left\{ \vec{v};\vec{m}\right\} \in\mathfrak{se}(3)$ and
\begin{subequations} 
\begin{align}
\mathscr{B}(\hat{m}) & =\mathbbm{1}_{3}+\frac{1-\cos|\vec{m}|}{|\vec{m}|^{2}}\hat{m}+\frac{|\vec{m}|-\sin|\vec{m}|}{|\vec{m}|^{3}}\hat{m}^{2}\label{eq:A}\\
\exp_{SO(3)} (\hat{m}) & =\mathbbm{1}_{3}+\frac{\sin|\vec{m}|}{|\vec{m}|}\hat{m}+\frac{1-\cos|\vec{m}|}{|\vec{m}|^{2}}\hat{m}^{2}\label{eq:B}
\end{align}
\end{subequations}
where $\exp_{SO(3)} (\hat{m}) \in SO(3)$ is an element of the special orthogonal
group in 3 dimensions. As Eq. \ref{eq:A} and Eq. \ref{eq:B} are
ill-conditioned for small $|\vec{m}|$, in numerics it is often prudent
to Taylor expand to at least $O(|\vec{m}|^6)$ when $|\vec{m}| < 0.1$ \citep{giusteriSimulationViscoelasticCosserat2021}.

A benefit of Eq.~\ref{eq:numerical schema for reconstruction of Cosserat rod} as a numerical solution schema is that it allows for flexibility in terms of when Eq.~\ref{eq:F spatial numerical eq} is evaluated. For example, in simulations we use a temporal discretisation $\Delta t$, but we can choose to only reconstruct the Cosserat rod at intervals $n \Delta t$, for some integer $n$.

\begin{comment}
We solve
\begin{subequations} 
\begin{align}
\mathcal{F}' & =  \mathcal{F}X \label{eq:F u} \\
\dot{\mathcal{F}} & = \mathcal{F} \label{eq:F t} Y.
\end{align}
\end{subequations}
in order to reconstruct $\mathcal{F}(t,u)$ from its infinitesimal description $\xi$. Formally, they have solutions
\begin{subequations} 
\begin{align}
\mathcal{F}_{ij}(u, \bar{t}) & = \mathcal{F}_{ik}(0, \bar{t}) \mathscr{U} \left\{ e^{ \int_0^u X(u, \bar{t}) du } \right\}_{kj} \\
\mathcal{F}_{ij}(\bar{u}, t) & = \mathcal{F}_{ik}(\bar{u}, 0) \mathscr{T} \left\{ e^{ \int_0^t Y(\bar{u}, t) dt } \right\}_{kj}
\end{align}
\end{subequations}
where $\mathscr{U}(\cdot)$ and $\mathscr{T}(\cdot)$ signifies the spatial and temporal time-ordered integral respectively. Numerically, these can be efficiently approximated by discretisation, and incrementally solved using the \textit{Magnus expansion}. Eq. \ref{eq:F u} and Eq. \ref{eq:F t}
can therefore be used together to trace out $\mathcal{F}$
from a single initial condition $\mathcal{F}(u_{0}, t_{0})$. Due to
the integrability of $\xi$, the value $\mathcal{F}(t, u)$ at $(t, u)$ is invariant with respect to which particular path
in $(t, u)$-space is taken. In light of this there are theoretically
an infinite number of reconstruction schemes. Below we propose what
we find to be the most convenient reconstruction scheme.

We discretise time and space as $u_{\alpha}=\alpha\Delta u,\ \alpha=0,\dots,N_{u}$, such that $u_{0}=t_{0}=0$ and $t_{\beta}=\beta\Delta t,\ \beta=0,\dots,N_{t}$
and $u_{N_{u}}=L_{0}$ and $t_{N_{t}}=T$. We define $\mathcal{F}^{\alpha,\beta}\approx\mathcal{F}(\alpha\Delta u,\beta\Delta t)$,
$X^{\alpha,\beta}\approx X(\alpha\Delta u,\beta\Delta t)$ and $Y^{\alpha,k}\approx Y(\alpha\Delta u,\beta\Delta t)$.
\begin{subequations} \label{eq:numerical schema for reconstruction of Cosserat rod}
\begin{align}
\mathcal{F}_{ij}^{0, \beta+1} & =\mathcal{F}_{ik}^{0, \beta} \exp_{SE(3)} \left(\Delta t\ N^{0, \beta}\right)_{kj}, & \mathcal{F}^{0,0}=\mathcal{F}^{(i)}\\
\mathcal{F}_{ij}^{\alpha+1, \beta} & =\mathcal{F}_{ik}^{\alpha, \beta}\exp_{SE(3)}  \left(\Delta u\ X^{\alpha,\beta}\right)_{kj} \label{eq:F spatial numerical eq}
\end{align}
\end{subequations}
with the initial condition $\mathcal{F}^{0,0}=\mathcal{F}^{(i)}$.
The matrix exponential has a closed-form analytical formula given
by
\begin{equation}
\exp_{SE(3)}  (H)=\left(\begin{array}{cc}
1 & \vec{0}^{T}\\
\mathscr{B}(\hat{m}) \vec{v} & \exp_{SO(3)}(\hat{m})
\end{array}\right)
\end{equation}
for $H=\left\{ \vec{v};\vec{m}\right\} \in\mathfrak{se}(3)$ and
\begin{subequations} 
\begin{align}
\mathscr{B}(\hat{m}) & =\mathbbm{1}_{3}+\frac{1-\cos|\vec{m}|}{|\vec{m}|^{2}}\hat{m}+\frac{|\vec{m}|-\sin|\vec{m}|}{|\vec{m}|^{3}}\hat{m}^{2}\label{eq:A}\\
\exp_{SO(3)} (\hat{m}) & =\mathbbm{1}_{3}+\frac{\sin|\vec{m}|}{|\vec{m}|}\hat{m}+\frac{1-\cos|\vec{m}|}{|\vec{m}|^{2}}\hat{m}^{2}\label{eq:B}
\end{align}
\end{subequations}
where $\exp_{SO(3)} (\hat{m}) \in SO(3)$ is an element of the special orthogonal
group in 3 dimensions. As Eq. \ref{eq:A} and Eq. \ref{eq:B} are
ill-conditioned for small $|\vec{m}|$, in numerics it is often prudent
to Taylor expand to at least $O(|\vec{m}|^6)$ when $|\vec{m}| < 0.1$ \citep{giusteriSimulationViscoelasticCosserat2021}.

A benefit of Eq.~\ref{eq:numerical schema for reconstruction of Cosserat rod} as a numerical solution schema is that it allows for flexibility in terms of when Eq.~\ref{eq:F spatial numerical eq} is evaluated. For example, in simulations we use a temporal discretisation $\Delta t$, but we can choose to only reconstruct the Cosserat rod at intervals $n \Delta t$, for some integer $n$.

\end{comment}



\chapter{Detailed derivation of the $SE(3)$ short-time propagator} \label{app:Detailed derivation of the SE(3) short-time propagator}

Here we provide detailed derivations of the results in Sec.~\ref{sec:Geometric integrators for SE(3)-valued configuration spaces}. Let $Y = \{ \vec{a} ; \vec{m} \} \in \mathfrak{se}(3)$, $N = \{ \vec{V} ; \vec{\Omega} \}$ and $\bar{\Delta} t = \Delta t - \Delta t'$, then
\begin{equation} \label{eq:E thingie SE(3)}
\begin{aligned}
	\mathscr{E}_{SE(3)}(\Delta t, N, Y) &  = \int_0^{\Delta t} \exp_{SE(3)}(-\bar{\Delta} t N) Y \exp_{SE(3)}(\bar{\Delta} t N) d \Delta t' \\
	& = \begin{pmatrix}
		0 & \vec{0}^T \\
		\circled{1} + \vec{r}(\Delta t, \vec{m}, \vec{V}) & \circled{2}
		\end{pmatrix}
\end{aligned}
\end{equation}
where we used Eq.~\ref{eq:SE(3) exp map}, and where
\begin{subequations}
	\begin{align}
	\circled{1} & = \int_0^{\Delta t} \exp_{SO(3)}(-\bar{\Delta} t \hat{\Omega}) \vec{a}\  d \Delta t' \\
	\circled{2} & = \int_0^{\Delta t} \exp_{SO(3)}(-\bar{\Delta} t \hat{\Omega}) \hat{m} \exp_{SO(3)}( \bar{\Delta} t \hat{\Omega})\ d \Delta t' \\
	\vec{r}(\Delta t, N, Y) & = \int_0^{\Delta t} \bar{\Delta} t \exp_{SO(3)}(-\bar{\Delta} t \hat{\Omega}) \hat{m} \mathscr{B}(\bar{\Delta} t \hat{\Omega}) \vec{V}  d \Delta t'.
	\end{align}
\end{subequations}
From the results of Sec.~\ref{sec:Geometric integrators for SO(3)-valued configuration spaces} we can make the identifications
\begin{subequations}
	\begin{align}
		\circled{1} & = \Delta t \mathscr{B}( - \Delta t \hat{\Omega}) \vec{a} \\
		\circled{2} & = \mathscr{E}_{SO(3)}(\Delta t, \hat{\Omega}, \hat{m}).
	\end{align}
\end{subequations}
where $\mathscr{B}(\hat{m})$ was defined in Eq.\ref{eq:SO(3) exp map}. It remains to evaluate $\vec{r}(\Delta t, N, Y)$. Let $\alpha = \Delta t' / \Delta t$, $\psi = \Delta t |\vec{\Omega}|$ and $\bar{\Omega} = \hat{\Omega} /|\vec{\Omega}|$ such that $(\Delta t - \Delta t') \hat{\Omega} = (1- \alpha) \psi \bar{\Omega}$. We rewrite $\vec{r}(\Delta t, N, Y)$ as
\begin{equation}
	\vec{r} (\Delta t, N, Y) = \int_0^1 \Delta t^2 (1-\alpha) \exp_{SO(3)}( - (1-\alpha) \psi \bar{\Omega}) \hat{m} \mathscr{B}((1-\alpha) \psi \bar{\Omega}) \vec{V} d \alpha.
\end{equation}
We now evaluate the integrand explicitly, we get
\begin{equation} \label{eq:SE(3) propagator calc 1}
	\Delta t^2 (1-\alpha) \exp_{SO(3)}( - (1-\alpha) \psi \bar{\Omega}) \hat{m} \mathscr{B}((1-\alpha) \psi \bar{\Omega})  = \Delta t^2 \sum_{i,j=1}^{3} P_{ij} \bar{\Omega}^{i-1} \hat{m} \bar{\Omega}^{j-1}
\end{equation}
where
\small
\begin{equation}
P = \begin{pmatrix}
\bar{\alpha} & \frac{\cos{\left(\bar{\alpha} \psi \right)} - 1}{\psi} & \bar{\alpha} - \frac{\sin{\left(\bar{\alpha} \psi \right)}}{\psi}\\\bar{\alpha} \sin{\left(\bar{\alpha} \psi \right)} & \frac{\left(\cos{\left(\bar{\alpha} \psi \right)} - 1\right) \sin{\left(\bar{\alpha} \psi \right)}}{\psi} & \frac{\left(\bar{\alpha} \psi - \sin{\left(\bar{\alpha} \psi \right)}\right) \sin{\left(\bar{\alpha} \psi \right)}}{\psi}\\\bar{\alpha} \left(1 - \cos{\left(\bar{\alpha} \psi \right)}\right) & - \frac{\left(\cos{\left(\bar{\alpha} \psi \right)} - 1\right)^{2}}{\psi} & 
\bar{\alpha} ( 1 - \cos{\left(\bar{\alpha} \psi \right)}) - 
\frac{ 2\sin{\left(\bar{\alpha} \psi \right)} + \sin{\left(2 \bar{\alpha} \psi \right)} }{2 \psi} 
\end{pmatrix}
\end{equation}
\normalsize
where the $i$th and $j$th indices of $P_{ij}$ signify rows and columns respectively and $\bar{\alpha} = 1 - \alpha$. We can now integrate each component $p_{ij}$ individually. We define
\footnotesize
\begin{equation} \label{eq:geometric integrator R matrix}
\begin{aligned}
	& R = \psi^2 \int_0^1 d\alpha P =  \\
	& \begin{pmatrix}
\frac{\psi^{2}}{2} & - \psi + \sin{\left(\psi \right)} & \frac{\psi^{2}}{2} + \cos{\left(\psi \right)} - 1\\
- \psi \cos{\left(\psi \right)} + \sin{\left(\psi \right)} & - \frac{\left(\cos{\left(\psi \right)} - 1\right)^{2}}{2} &
 - \psi \cos{\left(\psi \right)} - \frac{\psi}{2} 
 + \sin{\left(\psi \right)} + \frac{\sin{\left(2 \psi \right)}}{4}  \\
\frac{\psi^{2}}{2} - \psi \sin{\left(\psi \right)} - \cos{\left(\psi \right)} + 1 & - \frac{3 \psi}{2} + 2 \sin{\left(\psi \right)} - \frac{\sin{\left(2 \psi \right)}}{4} & \frac{\left(\psi - \sin{\left(\psi \right)}\right)^{2}}{2}
	\end{pmatrix},
\end{aligned}
\end{equation}
\normalsize
such that
\begin{equation} \label{eq:r function SE(3)}
	\vec{r}(\Delta t, N, \vec{m}) = \frac{1}{|\vec{\Omega}|^2} \sum_{i,j=1}^{3} R_{ij} \bar{\Omega}^{i-1} \hat{m} \bar{\Omega}^{j-1} \vec{V}.
\end{equation}
We made use of the symbolical manipulation package \emph{SymPy} \citep{meurerSymPySymbolicComputing2017} in order to find the expressions for $P$ and $R$. We will now express the short-term propagator Eq.~\ref{eq:kinodynamic short term propagators} in terms of the sub-matrices of $X_\alpha = \{ \vec{\theta}_\alpha, \vec{\pi}_\alpha \}$, $N = \{ \vec{V} ; \vec{\Omega} \}$ $S = \{ \vec{P} ; \vec{L} \}^*$ and $Q = \{ \vec{F} ; \vec{M} \}^*$. Firstly we define
\begin{subequations}
	\begin{align}
		X_\alpha(t_0, \mathbf{u}) & := X_{0,\alpha} = \{ \vec{\theta}_{\alpha,0} ; \vec{\pi}_{\alpha,0} \} \\
		N(t_0, \mathbf{u}) & := N_0 = \{ \vec{V}_0 ; \vec{\Omega}_0 \} \\
		S(t_0, \mathbf{u}) & := S_0 = \{ \vec{P}_0 ; \vec{L}_0 \}^* \\
		F_\alpha(t_0, \mathbf{u}) & := F_{0,\alpha} = \{ \vec{f}^1_{\alpha,0} ; \vec{f}^2_{\alpha,0} \} \\
		H(t_0, \mathbf{u}) & := H_0 = \{ \vec{h}^1_0 ; \vec{h}^2_0 \}^*
	\end{align}
\end{subequations}
where $F_\alpha$ and $H$ were defined in Eq.~\ref{eq:F H defs} using $Q^\alpha = \{ \vec{F}^\alpha ; \vec{M}^\alpha \}^*$, and
\begin{subequations}
	\begin{align}
		U^1_0 & = \exp_{SO(3)}(-\Delta t \hat{\Omega}_0) \\
		U^2_0 & = \mathscr{B}(- \Delta t \hat{\Omega}_0) \\
		\vec{s}_0(\vec{m}) & = \Delta t (U^1_0 \vec{m}) \times \left( U_0^2 \vec{V}_0 \right)
	\end{align}
\end{subequations}
where $\times$ denotes the cross product. Then we have that
\begin{subequations} \label{eq:SE(3) propagator calc 2}
\begin{align}
	\exp_{SE(3)}(-\Delta t N) X_{0,\alpha} \exp_{SE(3)}(\Delta t N) & = \begin{pmatrix}
		0 & \vec{0}^T \\
		U_0^1 \vec{\theta}_0 + \vec{s}_0(\vec{\pi}_{0,\alpha}) & \widehat{ U_0^1 \vec{\pi_{0,\alpha}} }
	\end{pmatrix} \\
	\exp_{SE(3)}(-\Delta t N) S_0^T \exp_{SE(3)}(\Delta t N) & = \begin{pmatrix}
		0 & \vec{0}^T \\
		U_0^1 \vec{P}_0 + \vec{s}_0(\vec{P}_0) & \widehat{ U_0^1 \vec{L_0} }	
	\end{pmatrix}.
\end{align}
\end{subequations}
Then, using Eq.~\ref{eq:SE(3) propagator calc 2} with Eq.~\ref{eq:E thingie SE(3)} we can expand Eq.~\ref{eq:kinodynamic short term propagators} as
\begin{subequations}
	\begin{align}
	\vec{\theta}_\alpha(t_0 + \Delta t, \mathbf{u}) & \approx U_0^1 \vec{\theta}_{0,\alpha} + \Delta t U_0^2 \vec{f}_{0,\alpha}^1 + \vec{s}_0(\vec{\pi}_{0,\alpha}) + \vec{r}(\Delta t, N_0, \vec{f}_{0,\alpha}^2) \\
	\vec{\pi}_\alpha(t_0 + \Delta t, \mathbf{u}) & \approx U_0^1 \vec{\pi}_{0,\alpha} + \mathscr{E}_{SO(3)}(\Delta t, \hat{\Omega}, \hat{f}_{0,\alpha}^2) \\
	\vec{P}(t_0 + \Delta t, \mathbf{u}) & \approx U_0^1 \vec{P}_{0\phantom{,\alpha}} + \Delta t U_0^2 \vec{h}_0^1 + \vec{s}_0(\vec{L}_0) + \vec{r}(\Delta t, N_0, \vec{h}_0^2) \\
	\vec{L}(t_0 + \Delta t, \mathbf{u}) & \approx U_0^1 \vec{L}_{0\phantom{,\alpha}} + \mathscr{E}_{SO(3)}(\Delta t, \hat{\Omega}, \hat{h}_0^2).
	\end{align}
\end{subequations} 

\section{Simplified integrator for $SE(3)$-configured systems} \label{app:Simplified integrator for SE(3)-configured systems}

The kinodynamic equations of an $SE(3)$-configured system, if expressed in terms of the sub-matrices of $X_\alpha$ and $S$, are
\begin{subequations}  \label{eq:components SE(3) kinodynamic}
\begin{align}
D_t \vec{\theta}_\alpha & = D_\alpha \vec{V} \\
\partial_t \vec{\pi}_\alpha & = D_\alpha \vec{\Omega} \\
D_t \vec{P} & = D_\alpha \vec{F}^\alpha + \vec{f}  \\
D_t \vec{L} & = D_\alpha \vec{M}^\alpha + \vec{\theta}_\alpha \times \vec{F}^\alpha + \vec{m}
\end{align}
\end{subequations}
where $D_t = \partial_t + \hat{\Omega}$ and $D_\alpha = \partial_\alpha + \hat{\pi}$ and $\alpha = 1,\dots,d$. We can construct a simplified short-term propagator by noting that each individual equation in Eq.~\ref{eq:components SE(3) kinodynamic} can be integrated using the propagator derived in Sec.~\ref{sec:Geometric integrators for SO(3)-valued configuration spaces}. To see that we rewrite Eq.~\ref{eq:components SE(3) kinodynamic} as
\begin{subequations}  \label{eq:components SE(3) kinodynamic rewritten}
\begin{align}
\partial_t \vec{\theta}_\alpha & = G_\alpha + A \vec{\theta}_\alpha \\
\partial_t \vec{\pi}_\alpha & = H_\alpha + A \vec{\pi}_\alpha \\
\partial_t \vec{P}_{\phantom{\alpha}} & = K_{\phantom{\alpha}} + A \vec{P} \\
\partial_t \vec{L}_{\phantom{\alpha}} & = J_{\phantom{\alpha}} + A \vec{Q}
\end{align}
\end{subequations}
where
\begin{subequations} 
\begin{align}
A_{\phantom{\alpha}} & = - \hat{\Omega} \\
G_\alpha & = D_\alpha \vec{V} \\
H_\alpha & = \partial_\alpha \vec{\Omega} \\
K_{\phantom{\alpha}} & = D_\alpha \vec{F}^\alpha + \vec{f} \\
J_{\phantom{\alpha}} & = D_\alpha \vec{M}^\alpha + \vec{\theta}_\alpha \times \vec{F}^\alpha + \vec{m}.
\end{align}
\end{subequations}
As $A \in \mathfrak{so}(3)$, the short-term propagator for each individual equation in Eq.~\ref{eq:components SE(3) kinodynamic rewritten} can now be found using the $SO(3)$-integrator defined in Sec.~\ref{sec:Geometric integrators for SO(3)-valued configuration spaces}. The resulting integrator requires far less computation (in particular, it does not require evaluating Eq.~\ref{eq:r function SE(3)}), however this comes at the cost of omitting the broader geometric properties of $SE(3)$.


\chapter{Non-dimensionalisation of the Cosserat rod equations of motion} \label{app:Nondimensionalisation of the Cosserat rod}

Here we will derive the non-dimensionalised kinodynamic equations of motion of an underdamped Cosserat rod (given in Eq.~\ref{eq:underdamped cosserat rod}), as well as an overdamped Cosserat rod (given in Eq.~\ref{eq:Cosserat rod overdamped dynamics}, in the absence of internal frictional and body forces. We set
\begin{align*}
\vec{\theta} & =\vec{\tilde{\theta}}\\
\vec{\pi} & =L_{0}^{-1}\vec{\tilde{\pi}}\\
\vec{V} & =\frac{L_{0}}{\tau}\vec{\tilde{V}}\\
\vec{\Omega} & =\tau^{-1}\vec{\tilde{\Omega}}\\
\vec{L} & =\frac{\rho_0 L_{0}^{2}}{\tau}\vec{\tilde{L}}\\
\vec{F} & =F_{0}\vec{\tilde{F}}\\
\vec{M} & =M_{0}\vec{\tilde{M}}
\end{align*}
where $\tau$, $F_{0}$ and $M_{0}$ are time, force and moment scales
that will be specified later. We also find that $\tilde{P} = \tilde{V}$. As $\vec{L}= \mathbb{I} \vec{\Omega}$, we also
define the dimensionless moment of inerta $\tilde{\mathbb{I}}=\frac{1}{\rho L_{0}^{2}}I$.
The resulting equations of motion become
\begin{align}
D_{\tilde{t}}\vec{\tilde{\theta}} & =D_{\tilde{u}}\vec{\tilde{V}}\\
\partial_{\tilde{t}}\vec{\pi} & =D_{\tilde{u}}\vec{\tilde{\Omega}}\\
\alpha^{T}D_{\tilde{t}}\vec{\tilde{P}} & =D_{\tilde{u}}\vec{\tilde{F}}-\beta^{T}\vec{\tilde{V}}\\
\alpha^{R}D_{\tilde{t}}\vec{\tilde{L}} & =D_{\tilde{u}}\vec{\tilde{M}}+\zeta\vec{\theta}\times\vec{\tilde{F}}-\zeta\lambda\vec{\tilde{\Omega}}
\end{align}
where
\begin{align*}
\alpha^{T} & =\frac{\rho L_{0}^{2}/\tau^{2}}{F_{0}}\\
\beta^{T} & =\frac{(L_{0}/\tau)\gamma_{T}}{F_{0}/L_{0}}\\
\alpha^{R} & =\frac{\rho L_{0}^{3}/\tau^{2}}{M_{0}}\\
\zeta & =\frac{F_{0}}{M_{0}/L_{0}}\\
\lambda & =\frac{\gamma_{R}}{\gamma_{T}L_{0}^{2}}
\end{align*}
$\alpha^{T}$ can be seen as the ratio of the characeristic inertial
forces compared to the characteristic internal force amplitude $F_{0}$, and we have assumed that the translational and rotation friction coefficients are scalar constants. $\beta^{T}$ is the ratio of the characteristic frictional force to
the internal force. $\alpha^{R}$ is the ratio of the characteristic
inertial moment to the characteristic moment amplitude $M_{0}$. $\zeta$
compares the characteristic force amplitude to the moment. $\lambda$
compares the translation to the rotational friction.

Without loss of generality we now set $\beta^{T}=1$, which means
$\tau=\frac{\gamma_{T}L_{0}^{2}}{F_{0}}$ which is the characteristic
damping time-scale for a simple harmonic oscillator. We also set $\zeta=1$,
which ensures that if $\vec{\tilde{F}}$ and $\vec{\tilde{M}}$ are
of the same order, then $\vec{F}$ and $\vec{M}/L_{0}$ are as well.
We also then have that $\alpha^{R}=\alpha^{T}=\alpha=\frac{\rho AL_{0}^{2}/\tau^{2}}{F_{0}}$
The resulting equations are
\begin{align}
D_{\tilde{t}}\vec{\tilde{\theta}} & =D_{\tilde{u}}\vec{\tilde{V}}\\
\partial_{\tilde{t}}\vec{\pi} & =D_{\tilde{u}}\vec{\tilde{\Omega}}\\
\alpha D_{\tilde{t}}\vec{\tilde{V}} & =D_{\tilde{u}}\vec{\tilde{F}}-\vec{\tilde{V}}\\
\alpha D_{\tilde{t}}\vec{\tilde{L}} & =D_{\tilde{u}}\vec{\tilde{M}}+\vec{\theta}\times\vec{\tilde{F}}-\lambda\vec{\tilde{\Omega}}
\end{align}
with two tunable parameters $\alpha$ and $\lambda$, as well as the
dimensionless moment of inertia $\tilde{I}$.

Let us now assume that we have constitutive laws
\begin{align*}
F_{i} & =g_{i}\theta_{i}\\
M_{i} & =\epsilon_{i}\pi_{i}
\end{align*}
then in non-dimensionalised form these become
\begin{align*}
\tilde{F}_{i} & =\tilde{g}_{i}\tilde{\theta}_{i}\\
\tilde{M}_{i} & =\tilde{\epsilon}_{i}\tilde{\pi}_{i}
\end{align*}
where $\tilde{g}_{i}=g_{i}/F_{0}$ and $\tilde{\epsilon}_{i}=\epsilon_{i}/(L_{0}M_{0})$. For overdamped systems we have $\alpha=0$, such that
\begin{align}
D_{\tilde{t}}\vec{\tilde{\theta}} & =D_{\tilde{u}}\vec{\tilde{V}}\\
\partial_{\tilde{t}}\vec{\pi} & =D_{\tilde{u}}\vec{\tilde{\Omega}}\\
\vec{\tilde{V}} & =D_{\tilde{u}}\vec{\tilde{F}}\nonumber \\
\lambda\vec{\tilde{\Omega}} & =D_{\tilde{u}}\vec{\tilde{M}}+\vec{\theta}\times\vec{\tilde{F}}
\end{align}



\chapter{Details of the geometric integrator benchmark simulations}

\section{Simulation of the Cosserat rod}

We simulated the Cosserat rod with overdamped and underdamped dynamics, specified in Eq.~\ref{eq:Cosserat rod overdamped dynamics} and Eq.~\ref{eq:underdamped cosserat rod} respectively. The non-dimensionalised equations of motion are given in App.~\ref{app:Nondimensionalisation of the Cosserat rod}. Henceforth all quantities will be assumed to be non-dimensional, and we will therefore omit the tilde-notation of App.~\ref{app:Nondimensionalisation of the Cosserat rod}. For overdamped dynamics we used $\lambda = 1$ and simulated for a duration of $T = 0.1$. For underdamped dynamics we used $\alpha = \lambda = 1$ and $T = 0.1$. The material coordinate took values in the unit interval $u \in [0,1]$.

To simulate the equations of motion of both systems we discretised space and time as
\begin{subequations}
	\begin{align} 
		u_i  & = i \Delta u, & i=0, \dots, N_u  \\
		t_i & = i \Delta t, & i=0, \dots, N_t
	\end{align}
\end{subequations}
where we used $\Delta u = 1/200$ for all simulations, such that $N_u = 200$. We ran simulations using a range of time-discretisations
\begin{equation} \label{eq:cosserat dts}
	\Delta t \in \mathcal{T} = \left\{ a 10^{-b}\ :\ a \in \{1, 1.25, 2, 2.5, 5 \} \text{ and } b \in \{ 4, \dots, 6 \} \right\}
\end{equation}
and for each $\Delta t$, we ran simulations where the rod was subject to a randomly configured force and moment, and starting with random initial conditions, as well as random moment of inertia for the underdamped system. We do not consider  the effects of internal frictionional or body forces.

The angular momentum, and the forces and moments were of the form
\begin{subequations}
	\begin{align}
		\vec{L} & = \mathbb{I} \vec{\Omega} \\
		\vec{F} & = \mathsf{K}^{(1)} (\vec{\theta} - \vec{\theta}_0) \\
		\vec{F} & = \mathsf{K}^{(2)} \vec{\pi}
	\end{align}
\end{subequations}
where $\mathbb{I}, \mathsf{K}^{(1)}, \mathsf{K}^{(2)} \in \mathbb{R}^{3 \times 3}$ were randomly generated each run using the code provided in Listing \ref{lst:random stiffness matrix}.

\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}
\lstset{framextopmargin=50pt,frame=bottomline}

\begin{lstlisting}[language=Python, caption=Generating random stiffness matrices and moment of inertia., label={lst:random stiffness matrix}]
import numpy as np
    
def random_pos_def_matrix():
    mat = np.random.random((3,3))
    mat = mat + mat.T
    mat += np.eye(3) * 3
    mat /= np.max(np.linalg.eigvals(mat))
    mat *= 1e-2
    return mat
    
# Generate random K1 matrix
K1 = random_pos_def_matrix()

# Generate random K2 matrix
K2 = random_pos_def_matrix()

# Generate random moment of inertia
mom_I = random_pos_def_matrix()
\end{lstlisting}

Initial configurations of the rod $\Phi_0 = (\mathbf{r}_0 ; E_0)$ were constructed by first generating a random closed center-line $\mathbf{r}_0(u)$ and its corresponding adapted frame, after which the latter was rotated into a deformed material frame $E_0(u)$. The random center-line was generated using a random superposition of sinusoidal functions, using the code provided in Listing ~\ref{lst:random centerline}.

\begin{lstlisting}[language=Python, caption=Generating random stiffness matrices and moment of inertia., label={lst:random centerline}]
N_random_curve_modes = 3
mu_random_curve = 0
sigma_random_curve = 0.1
L0 = 1
Nu = 200
us_grid = np.linspace(0, 1, Nu, endpoint=False)

def generate_random_periodic_function(dim, us, L, N, mu, sigma):
    fs = np.zeros((3, len(us)))
    dfs = np.zeros((3, len(us)))
    
    for i in range(dim):
        fs[i] += np.random.normal(mu, sigma)/2
        
        for j in range(1, N):
            a, b= np.random.normal(mu, sigma), np.random.normal(mu, sigma)
            
            fs[i] += a * np.cos((2*np.pi/L)*j*us) / (j*np.pi)
            fs[i] += b * np.sin((2*np.pi/L)*j*us) / (j*np.pi)
            
            dfs[i] += -(a * (2*np.pi/L)*j / (j*np.pi)) * np.sin((2*np.pi/L)*j*us)
            dfs[i] += (b * (2*np.pi/L)*j / (j*np.pi)) * np.cos((2*np.pi/L)*j*us)
            
    return fs, dfs

R0, dR0 = generate_random_periodic_function(dim, us_grid, L0, N_random_curve_modes, mu_random_curve, sigma_random_curve)
\end{lstlisting}

For a given center-line $\mathbf{r}_0(u)$ we can construct an adapted frame by computing
\begin{subequations}
\begin{align}
	 h & = |\partial_u \mathbf{r}| \\
	\mathbf{t} & = (\partial_u \mathbf{r}) / h \\
	\mathbf{n} & = (t_1 t_3, t_2 t_3, -t_1^2 - t_2^2)^T / \sqrt{ t_1^2 + t_3^2 +(t_1^2 + t_2^2)^2 } \\
	\mathbf{b} & = \mathbf{t} \times \mathbf{n}
\end{align}
\end{subequations}
which corresponds to a configuration $\Phi^\text{F} = (\mathbf{r} ; E^\text{F})$, where $E^\text{F} = (\mathbf{e}_1^\text{F}\ \mathbf{e}_2^\text{F}\ \mathbf{e}_3^\text{F})$. The corresponding spatial reconstruction field $X^\text{F} = \{ \vec{\pi}^\text{F}; \vec{\theta}^\text{F} \}$ of the adapted frame can be computed as
\begin{subequations}
	\begin{align}
		\pi_1^\text{F} & = (\partial_u \mathbf{n}) \cdot \mathbf{b} \\
		\pi_2^\text{F} & = - (\partial_u \mathbf{t}) \cdot \mathbf{b} \\
		\pi_3^\text{F} & = (\partial_u \mathbf{t}) \cdot \mathbf{n} \\
		\theta_1^\text{F} & = h\\
		\theta_2^\text{F} & = \theta_3^\text{F} = 0.
	\end{align}
\end{subequations}
Now, given some rotation matrix $R(u)$ defied over the length of the rod, we construct the initial configuration of the rod as 
\begin{subequations} \label{eq:deformation of rod}
	\begin{align}
		\hat{\pi}_0 & = (\partial_u R) R^T + R \hat{\pi}^\text{F} R^T \\
		\vec{\theta}_0 & = R \vec{\theta}^\text{F}.
	\end{align}
\end{subequations}
The form of these equations are such that the configuration $\Phi_0 = (\mathbf{r} ; E_0)$, which are the initial conditions used in the simulations, shares the same center-line with $\Phi^\text{F}$, where $E_0 = R E^\text{F}$. Equation \ref{eq:deformation of rod} can be found by substituting $E_0 = R E$ into Eq.~\ref{eq:eom for e_i along u}. Derivatives of the spatial reconstruction fields $X(t_i, u_i)$ and all other quantities were computed using Fourier transforms, following the numerical algorithms provided in \citep{trefethen2000spectral}.

The deformational rotation $R$ was constructed by generating random Euler angle-fields $\rho(u)$, $\phi(u)$ and $\psi(u)$ along $u \in [0, T]$, and then letting $R = R(\rho, \phi, \psi)$, where $R(\rho, \phi, \psi)$ is the mapping from Euler angles to rotation matrices. The Listing \ref{lst:random deformation R} shows the code that generates random deformations $R$.

\begin{lstlisting}[language=Python, caption=Generating random deformational rotation field., label={lst:random deformation R}]
N_R_modes = 3
mu_R = 0.1
sigma_R = 0.01

def eul2rot(rho, phi, psi) :
    R = np.zeros((3, 3, rho.shape[-1]))
    R[0,0] = np.cos(phi)*np.cos(psi)
    R[0,1] = np.sin(rho)*np.sin(phi)*np.cos(psi) - np.sin(psi)*np.cos(rho)
    R[0,2] = np.sin(phi)*np.cos(rho)*np.cos(psi) + np.sin(rho)*np.sin(psi)
    
    R[1,0] = np.sin(psi)*np.cos(phi)
    R[1,1] = np.sin(rho)*np.sin(phi)*np.sin(psi) + np.cos(rho)*np.cos(psi)
    R[1,2] = np.sin(phi)*np.sin(psi)*np.cos(rho) - np.sin(alprhoha)*np.cos(psi)
    
    R[2,0] = -np.sin(phi)
    R[2,1] = np.sin(rho)*np.cos(phi)
    R[2,2] = np.cos(rho)*np.cos(phi)

    return R

us_grid = np.linspace(0, 1, Nu, endpoint=False)
R_rho = generate_random_periodic_function(1, us, L0, N_rot_modes, mu_rot, sigma_rot)[0]
R_phi = generate_random_periodic_function(1, us, L0, N_rot_modes, mu_rot, sigma_rot)[0]
R_psi = generate_random_periodic_function(1, us, L0, N_rot_modes, mu_rot, sigma_rot)[0]

R = eul2rot(R_rho, R_phi, R_psi)
\end{lstlisting}

\begin{figure}[t]
\centering
        \includegraphics[width=0.8\textwidth]{figs_part2/benchmark_simulations/example_intial_rod_config}
        \caption{An example of a random initial configuration of the Cosserat rod generated by the outlined procedure. The blue line is the center-line $\mathbf{r}(u)$ and the red, green and blue lines attached to the center-line are $\mathbf{e}_1(u)$, $\mathbf{e}_2(u)$ and $\mathbf{e}_3(u)$ respectively.}
        \label{fig:example random initial cosserat configuration}
\end{figure}

This completes the description of the procedures used to generate the initial configurations of the Cosserat rod. See Fig.~\ref{fig:example random initial cosserat configuration} for an example of a random initial Cosserat configuration. For a given random configuration, which we will refer to via the index $\ell$, we ran simulations using the Forward-Euler (FEI), the $SE(3)$-integrator (SEI) and the simplified $SE(3)$ (SSEI) integrators for each $\Delta t \in \mathcal{T}$. Let $X^{I,\Delta t,\ell}$ be the result of a simulation using a given algorithm $I \in \{ \text{FEI}, \text{SEI}, \text{SSEI} \}$, time-step $\Delta t$ and initial configuration $\ell$. Using the algorithm described in App.~\ref{app:Reconstructing the Cosserat rod from xi} we can then reconstruct the corresponding spatio-temporal configuration $\Phi_\ell^{I,\Delta t,\ell} = (\mathbf{r}_\ell^{I, \Delta t,\ell} ; E_\ell^{I, \Delta t,\ell})$. We now define
\begin{subequations}
	\begin{align}
		\text{err}_\text{close}^{I, \Delta t, \ell} & = 
			|\mathbf{r}^{I, \Delta t, \ell}(T, 1) - \mathbf{r}^{I, \Delta t, \ell}(T, 0)|
			+ \sum_i |\mathbf{e}_i^{I, \Delta t, \ell}(T, 1) - \mathbf{e}_i^{I, \Delta t, \ell}(T, 0)|   \label{eq:cosserat close error}
	\end{align}
\end{subequations}
which measures the failure of the Cosserat rod to close. That is, $\text{err}_\text{close}^{I, \Delta t, \ell}$ is the magnitude of the discontinuity of $\Phi_\ell^{I,\Delta t,\ell}$ at $u=1$. As the initial configuration is a closed loop, we have $\mathbf{r}^{I, \Delta t, \ell}(0, 0) = \mathbf{r}^{I, \Delta t, \ell}(0, 1)$ for all simulations. Simulation errors will however in general cause the configuration of the Cosserat rod in the numerics to no longer close. Note that it is not sufficient for $X^{I,\Delta t,\ell}(t,u)$ to be a smooth periodic function of $u$ in order for $\Phi_\ell^{I,\Delta t,\ell}$ to be smooth a smooth function of $u$.

For both the underdamped and overdampded Cosserat rod, and for each $I$ and $\Delta t$ we ran $N_\text{sim} = 50$ simulations with random initial conditions $\ell = 1,\dots, N_\text{sim}$. We then computed the sample means and variances of the error
\begin{subequations}
	\begin{align}
		\langle \text{err}_\text{close}^{I, \Delta t} \rangle & = \frac{1}{N_\text{sim}} \sum_{\ell = 1}^{N_\text{sim}} \text{err}_\text{close}^{I, \Delta t, \ell} \\
		\text{Var}( \text{err}_\text{close}^{I, \Delta t}) & = \frac{1}{N_\text{sim}-1} \sum_{\ell = 1}^{N_\text{sim}} ( \text{err}_\text{close}^{I, \Delta t, \ell} - \langle \text{err}_\text{close}^{I, \Delta t} \rangle)^2.
	\end{align}
\end{subequations}

\begin{comment}
This completes the description of the procedures used to generate the initial configurations of the Cosserat rod. See Fig.~\ref{fig:example random initial cosserat configuration} for an example of a random initial Cosserat configuration. For a given random configuration, which we will refer to via the index $\ell$, we ran simulations using the Forward-Euler (FEI), the $SE(3)$-integrator (SEI) and the simplified $SE(3)$ (SSEI) integrators for each $\Delta t \in \mathcal{T}$. We also ran a reference simulation using the $SE(3)$-integrator at time-step $\Delta t_\text{ref} = 10^{-8}$. Let $X^{I,\Delta t,\ell}$ be the result of a simulation using a given algorithm $I \in \{ \text{FEI}, \text{SEI}, \text{SSEI} \}$, time-step $\Delta t$ and initial configuration $\ell$. Using the algorithm described in App.~\ref{app:Reconstructing the Cosserat rod from xi} we can then reconstruct the corresponding spatio-temporal configuration $\Phi_\ell^{I,\Delta t,\ell} = (\mathbf{r}_\ell^{I, \Delta t,\ell} ; E_\ell^{I, \Delta t,\ell})$. We now define
\begin{subequations}
	\begin{align}
		\text{err}_\text{ref}^{I, \Delta t, \ell} & = \sup_{i = 1, \dots, N_u} \left| \Phi_\ell^{I, \Delta t, \ell}(T, i \Delta u) - \Phi_\ell^{I, \Delta t_\text{ref}, \ell}(T, i \Delta u) \right| \label{eq:cosserat ref error} \\
		\text{err}_\text{close}^{I, \Delta t, \ell} & = |\mathbf{r}^{I, \Delta t, \ell}(T, 1) - \mathbf{r}^{I, \Delta t, \ell}(T, 0)|  \label{eq:cosserat close error}
	\end{align}
\end{subequations}
where we have defined $|\Phi| = |\mathbf{r}| + \sum_{i=1}^3 |\mathbf{e}_i|$. Equation \ref{eq:cosserat ref error} is the supremum over the residuals between the reference configuration $\Phi_\ell^{I, \Delta t_\text{ref}}$ and the $\Phi_\ell^{I, \Delta t}$. Equation \ref{eq:cosserat close error} measures the the difference between the initial and final point of the center-line. As the initial configuration is a closed loop, we have $\mathbf{r}^{I, \Delta t, \ell}(0, 0) = \mathbf{r}^{I, \Delta t, \ell}(0, 1)$ for all simulations. Numerical errors can however cause the loop to become unclosed.


For both the underdamped and overdampded Cosserat rod, and for each $I$ and $\Delta t$ we ran $N_\text{sim} = 50$ simulations with random initial conditions $\ell = 1,\dots, N_\text{sim}$. We then computed the sample mean and variances of the errors
\begin{subequations}
	\begin{align}
		\langle \text{err}_\text{ref}^{I, \Delta t} \rangle & = \frac{1}{N_\text{sim}} \sum_{\ell = 1}^{N_\text{sim}} \text{err}_\text{ref}^{I, \Delta t, \ell} \\
		\text{Var}( \text{err}_\text{ref}^{I, \Delta t}) & = \frac{1}{N_\text{sim}-1} \sum_{\ell = 1}^{N_\text{sim}} ( \text{err}_\text{ref}^{I, \Delta t, \ell} - \langle \text{err}_\text{ref}^{I, \Delta t} \rangle)^2.
	\end{align}
\end{subequations}
and
\begin{subequations}
	\begin{align}
		\langle \text{err}_\text{close}^{I, \Delta t} \rangle & = \frac{1}{N_\text{sim}} \sum_{\ell = 1}^{N_\text{sim}} \text{err}_\text{close}^{I, \Delta t, \ell} \\
		\text{Var}( \text{err}_\text{close}^{I, \Delta t}) & = \frac{1}{N_\text{sim}-1} \sum_{\ell = 1}^{N_\text{sim}} ( \text{err}_\text{close}^{I, \Delta t, \ell} - \langle \text{err}_\text{close}^{I, \Delta t} \rangle)^2.
	\end{align}
\end{subequations}
\end{comment}

\section{Simulation of the Cosserat surface}

We simulated the kinematic equations of motion of a Cosserat surface, which were given in Eq.~\ref{eq:cosserat surface eom}. We discretised space and time as
\begin{subequations}
	\begin{align} 
		u_i & = 1 - \cos \left( \frac{i \pi}{N} \right),\ i = 0, 1, \dots, N_u \label{eq:chebyshev nodes} \\
		v_i & = 1 - \cos \left( \frac{i \pi}{N} \right),\ i = 0, 1, \dots, N_v  \\
		t_i & = i \Delta t
	\end{align}
\end{subequations}
where Eq.~\ref{eq:chebyshev nodes} are known as the \textit{Chebyshev points}.\footnote{Eq.~\ref{eq:chebyshev nodes} is however in a non-standard form, as we have ordered the points in ascending order.} We differentiated functions on Chebyshev grids using \textit{spectral differentiation}, see \citep{trefethen2000spectral} for details. For all numerics we used $N_u = N_v = 20$.

To test our suite of integrators we evaluated their short-time propagators using a range of time-discretisations
\begin{equation} \label{eq:cosserat surface dts}
	\Delta t \in \mathcal{T} = \left\{ a 10^{-b}\ :\ a \in \{1, 1.25, 2, 2.5, 5 \} \text{ and } b \in \{ 4, \dots, 7 \} \right\}.
\end{equation}

Every short-term propagator was evaluated on the same initial condition $X_{0,\alpha}(u,v) = \{ \vec{\theta}_{0,\alpha}, \vec{\pi}_{0,\alpha} \},\ \alpha=u,v$, where
\begin{subequations}
	\begin{align}
		(\theta_{0,u})_2(i\Delta u, j \Delta u) & = 1 \\
		(\theta_{0,u})_1(i\Delta u, j \Delta u) & = (\theta_{0,u})_3(i\Delta u, j \Delta u) = 0 \\
		(\theta_{0,v})_3(i\Delta u, j \Delta u) & = 1 \\
		(\theta_{0,v})_1(i\Delta u, j \Delta u) & = (\theta_{0,v})_2(i\Delta u, j \Delta u) = 0 \\
		\vec{\pi}_{0,u}(i\Delta u, j \Delta u) & = \vec{\pi}_{0,v}(i\Delta u, j \Delta u) = 0
	\end{align}
\end{subequations}
for all $i = 0,\dots, N_u,\ j=0,\dots,N_v$. The corresponding spatio-temporal configuration $\Phi_0 = (\mathbf{r}, E)$ is a flat sheet $\mathbf{r}(i \Delta u, j \Delta u)  = (0, i \Delta u, j \Delta v )^T$ with a constant perpendicular material frame. The system is subject to generalised velocity field $N_0 = \{ \vec{V}_0, \vec{\Omega}_0 \}$ which we generate as a random superposition of sinusoidal surfaces, which can reproduces using Listing \ref{lst:cosserat surface initial conditions}.

\begin{lstlisting}[language=Python, caption=Setting up initial conditions nad generating random velocity fields., label={lst:cosserat surface initial conditions}]
# Parameters

Lu0 = 1
Lv0 = 1

Nu = 20
Nv = 20

N_rand_V_u = 5
N_rand_V_v = 5

N_rand_Omg_u = 5
N_rand_Omg_v = 5

rand_V_var = 1e0
rand_Omg_var = 1e0

# Initial conditions

thu0 = np.zeros((3, Nu, Nv))
thv0 = np.zeros((3, Nu, Nv))
piu0 = np.zeros((3, Nu, Nv))
piv0 = np.zeros((3, Nu, Nv))

thu0[1] = 1
thv0[2] = 1

piu0[1] = 0
piv0[0] = 0

# Construct material mesh grid

def get_grid_1D(Mm, L):
    N = Mm - 1
    x = np.cos(np.pi*np.arange(0,N+1)/N)
    x = L*(1-x)/2
    return x

us = get_grid_1D(Nu, Lu0)
vs = get_grid_1D(Nv, Lv0)
grid_U, grid_V = np.meshgrid(us, vs, indexing='ij')

# Define random velocity and and angular velocity

rand_V_coeffs = np.zeros((3, N_rand_V_u, N_rand_V_v))
rand_Omg_coeffs = np.zeros((3, N_rand_Omg_u, N_rand_Omg_v))

for di in range(dim):
    for i in range(N_rand_V_u):
        for j in range(N_rand_V_v):
            rand_V_coeffs[di,i,j] = rand_V_var * np.random.normal()
            rand_Omg_coeffs[di,i,j] = rand_Omg_var * np.random.normal()
            
# Compute velocity field

V_field = np.zeros((3, Nu, Nv))
for di in range(dim):
    for i in range(N_rand_V_u):
        for j in range(N_rand_V_v):
            V_field[di] += rand_V_coeffs[di,i,j] * np.sin((i - 0.5)*np.pi*grid_U/Lu0) * np.sin((j - 0.5)*np.pi*grid_V/Lv0) / ( (i-0.5) * (j - 0.5) * np.pi**2 )

# Compute angular velocity field

Omg_field = np.zeros((3, Nu, Nv))
for di in range(dim):
    for i in range(N_rand_Omg_u):
        for j in range(N_rand_Omg_v):
            Omg_field[di] += rand_Omg_coeffs[di,i,j] * np.sin((i - 0.5)*np.pi*grid_U/Lu0) * np.sin((j - 0.5)*np.pi*grid_V/Lv0) / ( (i-0.5) * (j - 0.5) * np.pi**2 )
\end{lstlisting}

Let $I \in \{ \text{FEI}, \text{SEI}, \text{SSEI} \}$ refer to the Forward-Euler, $SE(3)$- and simplified $SE(3)$-propagators respectively, and let $\ell = 1, \dots, N_\text{sim}$ be an index over the set of randomly generated velocity fields. In our results we used $N_\text{sim} = 50$. Let $X_{\Delta t, \alpha}^{I, \ell}$ be the result of computing the short-term propagator using integrator $I$, with time-step $\Delta t$ and configuration $\ell$. For each $I$, $\Delta t$ and $\ell$, we computed the supremum of the residual integrability error $\Delta^\text{int}_{u v}$, given in Eq.~\ref{eq:spatial integrability residual} over the material base space. In other words we compute
\begin{equation}
	\text{err}_\text{int}^{I, \Delta t, \ell} = \sup_{ i = 1,\dots,N_u,\ j = 1,\dots, N_v } \left| \partial_v X_{\Delta t, u}^{I, \ell} (i \Delta u, j \Delta v) - \mathcal{D}_u X_{\Delta t, v}^{I, \ell} (i \Delta u, j \Delta v).
 \right|
\end{equation}
where the derivatives were computed on the Chebyshev grid using spectral differentiation. We also compute the mean and variance of the integrability error over the set of configurations $\ell$
\begin{subequations}
	\begin{align}
		\langle \text{err}_\text{int}^{I, \Delta t} \rangle & = \frac{1}{N_\text{sim}} \sum_{\ell = 1}^{N_\text{sim}} \text{err}_\text{int}^{I, \Delta t, \ell} \\
		\text{Var}( \text{err}_\text{int}^{I, \Delta t}) & = \frac{1}{N_\text{sim}-1} \sum_{\ell = 1}^{N_\text{sim}} ( \text{err}_\text{int}^{I, \Delta t, \ell} - \langle \text{err}_\text{ref}^{I, \Delta t} \rangle)^2.
	\end{align}
\end{subequations}



\begin{comment}
\chapter*{Notation} \label{app:glossary of notation}
\addcontentsline{toc}{chapter}{Notation}

%Vectors will be denoted in both as $\mathbf{v}$ and $\vec{v}$, with components $v_i$. We write the Euclidean norm of a vector as $|\mathbf{v}| = |\vec{v}|$. 


Functions $f$ are maps $f : A \to B$, where $A$ and $B$ are the domain and codomain of the function respectively. If $a \in A$ then $f(a) \in B$. We denote and define the image of a function as $f(A) = \{ f(a)\ :\ a \in B \}$. We denote that a map $f : \mathbb{R} \to \mathbb{R}$ is $k$-times differentiable as $f \in C^k$. The function $f$ is continuous if $f \in C^0$, and smooth if $f \in C^\infty$. This extends to functions on $\mathbb{R}^d$.

\section*{Notation specific to Part I}



Measure, density, law




$C^0_{\mathbf{x}_0}([0,T])$




Let $P$ be the probability density of $\mathbb{P}$ with respect to the Lebesgue measure, and we will henceforth write this relation as $P \sim \mathbb{P}$.


$(Z_i)_j \sim \mathcal{N}(0, 2D)$

$\mathcal{N}(0, \mathbbm{1}_d)$

$\mathcal{N}(0, \mathcal{C})$ for infinite dimensional operators.s

$\langle X \rangle $


$\langle\mathbf{f},\mathbf{g}\rangle=\sum_{i}\int_{0}^{T}f_{i}(t)g_{i}(t)dt$

\section*{Part II notation}

Euclidean vectors are written in boldface as $\mathbf{v} \in \mathbb{E}^d$, where $\mathbb{E}^d$ is $d$-dimensional Euclidean space, with inner product $\mathbf{v} \cdot \mathbf{w}$ for $\mathbf{w} \in \mathbb{E}^d$. We write column vectors as $\vec{v} \in \mathbb{R}^d$, with components $\vec{v} = (v_1\ v_2\ \dots\ v_d)^T$.
  

Matrix derivatives are carried out using the numerator-layout convention. For a matrix $X \in \mathbb{R}^{p \times q}$ and $y(X)$ a scalar function, then
\begin{equation} \label{eq:numerator-layout convention}
	\frac{\partial y}{\partial X} = \begin{pmatrix}
		\frac{\partial y}{\partial X_{11}} & \frac{\partial y}{\partial X_{21}} & \dots & \frac{\partial y}{\partial X_{p1}} \\
		\frac{\partial y}{\partial X_{12}} & \frac{\partial y}{\partial X_{22}} & \dots & \frac{\partial y}{\partial X_{p2}} \\
		 \vdots & \ddots & \vdots \\
		 \frac{\partial y}{\partial X_{1q}} & \frac{\partial y}{\partial X_{2q}} & \dots & \frac{\partial y}{\partial X_{pq}}
	\end{pmatrix}
\end{equation}.
For $\vec{x} \in \mathbb{R}^d$
\begin{equation}
	\frac{\partial y}{\partial \vec{x}} = \begin{pmatrix}
		\frac{\partial y}{\partial x_1} \\
		\frac{\partial y}{\partial x_2} \\
		\vdots \\
		\frac{\partial y}{\partial x_p}
	\end{pmatrix}
\end{equation}

Often we will abbreviate partial derivatives as
\begin{equation}
\begin{aligned}
\partial_u f & := \frac{\partial f}{\partial u} \\
\partial_t f & := \frac{\partial f}{\partial t}
\end{aligned}
\end{equation}
or
\begin{equation}
\begin{aligned}
f' & := \frac{\partial f}{\partial u} \\
\dot{f} & := \frac{\partial f}{\partial t}
\end{aligned}.
\end{equation}
This applies to both scalar, vectorial and group-valued functions. 

If we have multiple coordinates, derivatives will be denoted by subscripts i.e. $f_u$, $f_t$ etc. or $\partial_\alpha = \frac{\partial}{\partial u^\alpha}$.

In any dimension $d$ we will assume that $\mathbb{R}^d$ is a vector space equipped with the standard Euclidean metric. Vectors $\mathbf{a} \in \mathbb{R}^d$ will be written as column vectors $\mathbf{a} = (a_1\ a_2\ \dots\ a_d)^T$, and their inner product will often be written as
\begin{equation}
\mathbf{a} \cdot \mathbf{b} = \mathbf{a}^T \mathbf{b}
\end{equation}
interchangeably.

which for any two vectors $\mathbf{a},\mathbf{b}\in \mathbb{R}^d$ can be written in several different ways interchangeably:
\begin{equation}
\mathbf{a} \cdot \mathbf{b} = \mathbf{a}^T \mathbf{b}
\end{equation}


We will often distinguish $\mathbb{E}^d$ and $\mathbb{R}^d$. 



Introduce the vec notation here as well, and tilde notation $\tilde{v}$, and do it clearly and in detail.

$e$ is the identity of Lie groups.

introduce the hatmap and give it explicitly (and use the vec notation). 

\begin{equation} \label{eq:hat map}
\hat{v} =  \begin{pmatrix}
0 & -v_3 & v_2 \\
v_3 & 0 & - v_1 \\
- v_2 & v_1 & 0
\end{pmatrix}
\end{equation}

also have that $\vec{\cdot}$ signifes the inverse hatmap for anti-symmetric 3x3 matrices. So $\vec{\hat{v}} \in \mathbb{R}^{3}$.

$\hat{v} = v \times$

$x \times y = - y \times x =  \hat{y} x$

$\mathbb{1}$ identity matrix



$X = \{ \vec{a} ; \vec{b} \}$


Matrix derivatives, and the fact that we only take them with respect to the non-zero values. $A_{ji} = \frac{\partial U}{\partial B_{ij}}$.

$\bigwedge_{\beta \neq \alpha}$

closure of sets $\bar{U}$.



\begin{equation}
	\{ \vec{a}, \vec{m} \} = \begin{pmatrix}
		0 & \vec{0}^T \\
		\vec{a} & \hat{m}
	\end{pmatrix} \in \mathfrak{se}(3)
\end{equation}
where $\vec{a}, \vec{m} \in \mathbb{R}^3$, and $\vec{0} = (0\ 0\ 0)^T$.
\begin{equation}
	\{ \vec{b}, \vec{n} \}^* = \begin{pmatrix}
		0 & \vec{b}^T \\
		\vec{0} & \hat{n}^T
	\end{pmatrix} \in \mathfrak{se}^*(3)
\end{equation}
where $\vec{b}, \vec{n} \in \mathbb{R}^3$

\end{comment}


%\end{appendices}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Index:
%%
%\printthesisindex

\end{document}
